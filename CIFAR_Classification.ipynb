{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPU/tCbRECJh3y22UqWl04b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yog-Sothothe/DL-Project-1/blob/main/CIFAR_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Previous Version"
      ],
      "metadata": {
        "id": "qKpiw0YLtInN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YRBRCLd7rHRI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Squeeze-and-Excitation Block\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channels, channels // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channels // reduction, channels, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        # Squeeze\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        # Excitation\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        # Scale\n",
        "        return x * y"
      ],
      "metadata": {
        "id": "zaE9hbDFrYJK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-Activation block with SE module\n",
        "class PreActSEBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, reduction=16, drop_prob=0.0):\n",
        "        super(PreActSEBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False)\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "        # Add the SE module in the residual block\n",
        "        self.se = SEBlock(planes, reduction)\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(x))\n",
        "        # When shortcut is not Identity, use out as input\n",
        "        shortcut = self.shortcut(out) if not isinstance(self.shortcut, nn.Identity) else x\n",
        "        out = self.conv1(out)\n",
        "        out = self.conv2(F.relu(self.bn2(out)))\n",
        "        # Incorporate channel attention using the SE module\n",
        "        out = self.se(out)\n",
        "        # Stochastic depth\n",
        "        if self.training:\n",
        "            if torch.rand(1).item() < self.drop_prob:\n",
        "                return shortcut\n",
        "            else:\n",
        "                out = out / (1 - self.drop_prob)\n",
        "        out += shortcut\n",
        "        return out\n",
        "\n",
        "# Construct ResNet with PreActSEBlock\n",
        "# Stochastic depth\n",
        "class PreActSEResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10, base_channels=64, max_drop_prob=0.1):\n",
        "        super(PreActSEResNet, self).__init__()\n",
        "        self.in_planes = base_channels\n",
        "\n",
        "        self.max_drop_prob = max_drop_prob\n",
        "        self.total_blocks = sum(num_blocks)\n",
        "        self.current_block = 0\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, base_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.layer1 = self._make_layer(block, base_channels,  num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, base_channels * 2, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, base_channels * 4, num_blocks[2], stride=2)\n",
        "        self.bn   = nn.BatchNorm2d(base_channels * 4)\n",
        "        self.linear = nn.Linear(base_channels * 4 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for s in strides:\n",
        "            # Linear increasing drop rate\n",
        "            layers.append(block(self.in_planes, planes, s, drop_prob=(self.max_drop_prob * self.current_block / (self.total_blocks - 1)\n",
        "                         if self.total_blocks > 1 else 0.0)))\n",
        "            self.in_planes = planes * block.expansion\n",
        "            self.current_block += 1\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = F.relu(self.bn(out))\n",
        "        out = F.avg_pool2d(out, out.size(3))\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def PreActSEResNet20():\n",
        "    return PreActSEResNet(PreActSEBlock, [3, 3, 3])"
      ],
      "metadata": {
        "id": "W_tudfkGrckr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uerQM28L0YnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mixup augmentation\n",
        "def mixup_data(x, y, alpha=1.0):\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1.0\n",
        "    batch_size = x.size(0)\n",
        "    index = torch.randperm(batch_size).to(x.device)\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def rand_bbox(size, lam):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = int(W * cut_rat)\n",
        "    cut_h = int(H * cut_rat)\n",
        "\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "\n",
        "# CutMix augmentation\n",
        "def cutmix_data(x, y, alpha=1.0):\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1.0\n",
        "\n",
        "    batch_size = x.size(0)\n",
        "    index = torch.randperm(batch_size).to(x.device)\n",
        "\n",
        "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
        "    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n",
        "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size(-1) * x.size(-2)))\n",
        "\n",
        "    y_a, y_b = y, y[index]\n",
        "    return x, y_a, y_b, lam"
      ],
      "metadata": {
        "id": "Tb7HYH-LrhOd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    transform_train = T.Compose([\n",
        "        T.RandomCrop(32, padding=4),\n",
        "        T.RandomHorizontalFlip(),\n",
        "        T.AutoAugment(policy=T.AutoAugmentPolicy.CIFAR10),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
        "        T.RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.3, 3.3))\n",
        "    ])\n",
        "    transform_test = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    net = PreActSEResNet20().to(device)\n",
        "\n",
        "    total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
        "    print(\"Total parameters:\", total_params)\n",
        "    if total_params > 5e6:\n",
        "        print(\"Our model is too fat and exceeds 5M parameters!\")\n",
        "        exit(1)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "    num_epochs = 500\n",
        "    # Learning rate scheduler (cosine annealing)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "    train_loss_per_epoch = []\n",
        "    test_acc_per_epoch = []\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        epoch_loss = 0.0\n",
        "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Mixup/CutMix\n",
        "            if np.random.rand() < 0.5:\n",
        "                images, targets_a, targets_b, lam = mixup_data(inputs, targets, alpha=1.0)\n",
        "            else:\n",
        "                images, targets_a, targets_b, lam = cutmix_data(inputs, targets, alpha=1.0)\n",
        "\n",
        "            outputs = net(images)\n",
        "            loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            if (batch_idx + 1) %50 == 0:\n",
        "                print(f\"Epoch {epoch+1}, Batch {batch_idx+1}: Loss {running_loss / 50:.3f}\")\n",
        "                running_loss = 0.0\n",
        "\n",
        "        avg_train_loss = epoch_loss / len(trainloader)\n",
        "        train_loss_per_epoch.append(avg_train_loss)\n",
        "        print(f\"Epoch {epoch+1}: Train Loss: {avg_train_loss:.3f}\")\n",
        "\n",
        "        net.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in testloader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = net(inputs)\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += targets.size(0)\n",
        "                correct += predicted.eq(targets).sum().item()\n",
        "        test_acc = 100. * correct / total\n",
        "        test_acc_per_epoch.append(test_acc)\n",
        "        print(f\"Epoch {epoch+1}: Test Accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "        # Step the scheduler each epoch\n",
        "        scheduler.step()\n",
        "\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            torch.save(net.state_dict(), f'./model_epoch_{epoch+1}.pth')\n",
        "            print(f\"Model saved at epoch {epoch+1}.\")\n",
        "\n",
        "    print(\"Training finished!\")\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, num_epochs+1), train_loss_per_epoch, label=\"Training Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training Loss Curve\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, num_epochs+1), test_acc_per_epoch, label=\"Test Accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.title(\"Test Accuracy Curve\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    final_train_loss = train_loss_per_epoch[-1]\n",
        "    final_test_acc = test_acc_per_epoch[-1]\n",
        "\n",
        "    print(f\"Final Training Loss: {final_train_loss:.3f}\")\n",
        "    print(f\"Final Test Accuracy: {final_test_acc:.2f}%\")\n",
        "    print(f\"Total Trainable Parameters: {total_params}\")"
      ],
      "metadata": {
        "id": "M2etHaqgrjwk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "95bcca5c-6e76-43b2-f9d8-a3c7012c12d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Total parameters: 4359242\n",
            "Epoch 1, Batch 50: Loss 2.227\n",
            "Epoch 1, Batch 100: Loss 2.132\n",
            "Epoch 1, Batch 150: Loss 2.063\n",
            "Epoch 1: Train Loss: 2.109\n",
            "Epoch 1: Test Accuracy: 44.80%\n",
            "Epoch 2, Batch 50: Loss 1.974\n",
            "Epoch 2, Batch 100: Loss 1.915\n",
            "Epoch 2, Batch 150: Loss 1.853\n",
            "Epoch 2: Train Loss: 1.904\n",
            "Epoch 2: Test Accuracy: 54.61%\n",
            "Epoch 3, Batch 50: Loss 1.797\n",
            "Epoch 3, Batch 100: Loss 1.799\n",
            "Epoch 3, Batch 150: Loss 1.758\n",
            "Epoch 3: Train Loss: 1.785\n",
            "Epoch 3: Test Accuracy: 61.38%\n",
            "Epoch 4, Batch 50: Loss 1.773\n",
            "Epoch 4, Batch 100: Loss 1.795\n",
            "Epoch 4, Batch 150: Loss 1.732\n",
            "Epoch 4: Train Loss: 1.749\n",
            "Epoch 4: Test Accuracy: 53.17%\n",
            "Epoch 5, Batch 50: Loss 1.671\n",
            "Epoch 5, Batch 100: Loss 1.659\n",
            "Epoch 5, Batch 150: Loss 1.696\n",
            "Epoch 5: Train Loss: 1.678\n",
            "Epoch 5: Test Accuracy: 65.06%\n",
            "Model saved at epoch 5.\n",
            "Epoch 6, Batch 50: Loss 1.643\n",
            "Epoch 6, Batch 100: Loss 1.577\n",
            "Epoch 6, Batch 150: Loss 1.690\n",
            "Epoch 6: Train Loss: 1.635\n",
            "Epoch 6: Test Accuracy: 68.73%\n",
            "Epoch 7, Batch 50: Loss 1.621\n",
            "Epoch 7, Batch 100: Loss 1.576\n",
            "Epoch 7, Batch 150: Loss 1.567\n",
            "Epoch 7: Train Loss: 1.605\n",
            "Epoch 7: Test Accuracy: 74.05%\n",
            "Epoch 8, Batch 50: Loss 1.647\n",
            "Epoch 8, Batch 100: Loss 1.586\n",
            "Epoch 8, Batch 150: Loss 1.562\n",
            "Epoch 8: Train Loss: 1.568\n",
            "Epoch 8: Test Accuracy: 74.09%\n",
            "Epoch 9, Batch 50: Loss 1.494\n",
            "Epoch 9, Batch 100: Loss 1.580\n",
            "Epoch 9, Batch 150: Loss 1.483\n",
            "Epoch 9: Train Loss: 1.530\n",
            "Epoch 9: Test Accuracy: 73.88%\n",
            "Epoch 10, Batch 50: Loss 1.504\n",
            "Epoch 10, Batch 100: Loss 1.569\n",
            "Epoch 10, Batch 150: Loss 1.515\n",
            "Epoch 10: Train Loss: 1.521\n",
            "Epoch 10: Test Accuracy: 77.58%\n",
            "Model saved at epoch 10.\n",
            "Epoch 11, Batch 50: Loss 1.546\n",
            "Epoch 11, Batch 100: Loss 1.456\n",
            "Epoch 11, Batch 150: Loss 1.508\n",
            "Epoch 11: Train Loss: 1.500\n",
            "Epoch 11: Test Accuracy: 75.76%\n",
            "Epoch 12, Batch 50: Loss 1.504\n",
            "Epoch 12, Batch 100: Loss 1.546\n",
            "Epoch 12, Batch 150: Loss 1.525\n",
            "Epoch 12: Train Loss: 1.502\n",
            "Epoch 12: Test Accuracy: 71.40%\n",
            "Epoch 13, Batch 50: Loss 1.543\n",
            "Epoch 13, Batch 100: Loss 1.458\n",
            "Epoch 13, Batch 150: Loss 1.477\n",
            "Epoch 13: Train Loss: 1.484\n",
            "Epoch 13: Test Accuracy: 77.31%\n",
            "Epoch 14, Batch 50: Loss 1.471\n",
            "Epoch 14, Batch 100: Loss 1.448\n",
            "Epoch 14, Batch 150: Loss 1.538\n",
            "Epoch 14: Train Loss: 1.478\n",
            "Epoch 14: Test Accuracy: 81.19%\n",
            "Epoch 15, Batch 50: Loss 1.403\n",
            "Epoch 15, Batch 100: Loss 1.408\n",
            "Epoch 15, Batch 150: Loss 1.430\n",
            "Epoch 15: Train Loss: 1.402\n",
            "Epoch 15: Test Accuracy: 81.53%\n",
            "Model saved at epoch 15.\n",
            "Epoch 16, Batch 50: Loss 1.392\n",
            "Epoch 16, Batch 100: Loss 1.387\n",
            "Epoch 16, Batch 150: Loss 1.500\n",
            "Epoch 16: Train Loss: 1.430\n",
            "Epoch 16: Test Accuracy: 82.80%\n",
            "Epoch 17, Batch 50: Loss 1.443\n",
            "Epoch 17, Batch 100: Loss 1.431\n",
            "Epoch 17, Batch 150: Loss 1.403\n",
            "Epoch 17: Train Loss: 1.413\n",
            "Epoch 17: Test Accuracy: 83.95%\n",
            "Epoch 18, Batch 50: Loss 1.361\n",
            "Epoch 18, Batch 100: Loss 1.387\n",
            "Epoch 18, Batch 150: Loss 1.448\n",
            "Epoch 18: Train Loss: 1.398\n",
            "Epoch 18: Test Accuracy: 82.98%\n",
            "Epoch 19, Batch 50: Loss 1.397\n",
            "Epoch 19, Batch 100: Loss 1.434\n",
            "Epoch 19, Batch 150: Loss 1.365\n",
            "Epoch 19: Train Loss: 1.396\n",
            "Epoch 19: Test Accuracy: 84.91%\n",
            "Epoch 20, Batch 50: Loss 1.331\n",
            "Epoch 20, Batch 100: Loss 1.362\n",
            "Epoch 20, Batch 150: Loss 1.372\n",
            "Epoch 20: Train Loss: 1.350\n",
            "Epoch 20: Test Accuracy: 82.70%\n",
            "Model saved at epoch 20.\n",
            "Epoch 21, Batch 50: Loss 1.366\n",
            "Epoch 21, Batch 100: Loss 1.342\n",
            "Epoch 21, Batch 150: Loss 1.306\n",
            "Epoch 21: Train Loss: 1.342\n",
            "Epoch 21: Test Accuracy: 82.69%\n",
            "Epoch 22, Batch 50: Loss 1.373\n",
            "Epoch 22, Batch 100: Loss 1.317\n",
            "Epoch 22, Batch 150: Loss 1.357\n",
            "Epoch 22: Train Loss: 1.348\n",
            "Epoch 22: Test Accuracy: 85.13%\n",
            "Epoch 23, Batch 50: Loss 1.392\n",
            "Epoch 23, Batch 100: Loss 1.311\n",
            "Epoch 23, Batch 150: Loss 1.407\n",
            "Epoch 23: Train Loss: 1.361\n",
            "Epoch 23: Test Accuracy: 81.21%\n",
            "Epoch 24, Batch 50: Loss 1.352\n",
            "Epoch 24, Batch 100: Loss 1.409\n",
            "Epoch 24, Batch 150: Loss 1.308\n",
            "Epoch 24: Train Loss: 1.359\n",
            "Epoch 24: Test Accuracy: 86.09%\n",
            "Epoch 25, Batch 50: Loss 1.395\n",
            "Epoch 25, Batch 100: Loss 1.334\n",
            "Epoch 25, Batch 150: Loss 1.404\n",
            "Epoch 25: Train Loss: 1.371\n",
            "Epoch 25: Test Accuracy: 87.13%\n",
            "Model saved at epoch 25.\n",
            "Epoch 26, Batch 50: Loss 1.310\n",
            "Epoch 26, Batch 100: Loss 1.327\n",
            "Epoch 26, Batch 150: Loss 1.350\n",
            "Epoch 26: Train Loss: 1.333\n",
            "Epoch 26: Test Accuracy: 84.58%\n",
            "Epoch 27, Batch 50: Loss 1.420\n",
            "Epoch 27, Batch 100: Loss 1.303\n",
            "Epoch 27, Batch 150: Loss 1.200\n",
            "Epoch 27: Train Loss: 1.323\n",
            "Epoch 27: Test Accuracy: 85.35%\n",
            "Epoch 28, Batch 50: Loss 1.330\n",
            "Epoch 28, Batch 100: Loss 1.301\n",
            "Epoch 28, Batch 150: Loss 1.284\n",
            "Epoch 28: Train Loss: 1.310\n",
            "Epoch 28: Test Accuracy: 87.75%\n",
            "Epoch 29, Batch 50: Loss 1.337\n",
            "Epoch 29, Batch 100: Loss 1.311\n",
            "Epoch 29, Batch 150: Loss 1.312\n",
            "Epoch 29: Train Loss: 1.319\n",
            "Epoch 29: Test Accuracy: 87.67%\n",
            "Epoch 30, Batch 50: Loss 1.306\n",
            "Epoch 30, Batch 100: Loss 1.340\n",
            "Epoch 30, Batch 150: Loss 1.310\n",
            "Epoch 30: Train Loss: 1.313\n",
            "Epoch 30: Test Accuracy: 89.16%\n",
            "Model saved at epoch 30.\n",
            "Epoch 31, Batch 50: Loss 1.244\n",
            "Epoch 31, Batch 100: Loss 1.326\n",
            "Epoch 31, Batch 150: Loss 1.299\n",
            "Epoch 31: Train Loss: 1.292\n",
            "Epoch 31: Test Accuracy: 84.02%\n",
            "Epoch 32, Batch 50: Loss 1.303\n",
            "Epoch 32, Batch 100: Loss 1.316\n",
            "Epoch 32, Batch 150: Loss 1.258\n",
            "Epoch 32: Train Loss: 1.270\n",
            "Epoch 32: Test Accuracy: 88.48%\n",
            "Epoch 33, Batch 50: Loss 1.329\n",
            "Epoch 33, Batch 100: Loss 1.198\n",
            "Epoch 33, Batch 150: Loss 1.279\n",
            "Epoch 33: Train Loss: 1.275\n",
            "Epoch 33: Test Accuracy: 88.99%\n",
            "Epoch 34, Batch 50: Loss 1.345\n",
            "Epoch 34, Batch 100: Loss 1.281\n",
            "Epoch 34, Batch 150: Loss 1.218\n",
            "Epoch 34: Train Loss: 1.263\n",
            "Epoch 34: Test Accuracy: 88.26%\n",
            "Epoch 35, Batch 50: Loss 1.276\n",
            "Epoch 35, Batch 100: Loss 1.256\n",
            "Epoch 35, Batch 150: Loss 1.307\n",
            "Epoch 35: Train Loss: 1.279\n",
            "Epoch 35: Test Accuracy: 88.51%\n",
            "Model saved at epoch 35.\n",
            "Epoch 36, Batch 50: Loss 1.320\n",
            "Epoch 36, Batch 100: Loss 1.301\n",
            "Epoch 36, Batch 150: Loss 1.276\n",
            "Epoch 36: Train Loss: 1.295\n",
            "Epoch 36: Test Accuracy: 88.58%\n",
            "Epoch 37, Batch 50: Loss 1.261\n",
            "Epoch 37, Batch 100: Loss 1.275\n",
            "Epoch 37, Batch 150: Loss 1.341\n",
            "Epoch 37: Train Loss: 1.280\n",
            "Epoch 37: Test Accuracy: 89.96%\n",
            "Epoch 38, Batch 50: Loss 1.323\n",
            "Epoch 38, Batch 100: Loss 1.282\n",
            "Epoch 38, Batch 150: Loss 1.343\n",
            "Epoch 38: Train Loss: 1.296\n",
            "Epoch 38: Test Accuracy: 87.62%\n",
            "Epoch 39, Batch 50: Loss 1.265\n",
            "Epoch 39, Batch 100: Loss 1.342\n",
            "Epoch 39, Batch 150: Loss 1.296\n",
            "Epoch 39: Train Loss: 1.314\n",
            "Epoch 39: Test Accuracy: 88.45%\n",
            "Epoch 40, Batch 50: Loss 1.247\n",
            "Epoch 40, Batch 100: Loss 1.295\n",
            "Epoch 40, Batch 150: Loss 1.337\n",
            "Epoch 40: Train Loss: 1.295\n",
            "Epoch 40: Test Accuracy: 87.51%\n",
            "Model saved at epoch 40.\n",
            "Epoch 41, Batch 50: Loss 1.270\n",
            "Epoch 41, Batch 100: Loss 1.283\n",
            "Epoch 41, Batch 150: Loss 1.272\n",
            "Epoch 41: Train Loss: 1.269\n",
            "Epoch 41: Test Accuracy: 88.93%\n",
            "Epoch 42, Batch 50: Loss 1.276\n",
            "Epoch 42, Batch 100: Loss 1.209\n",
            "Epoch 42, Batch 150: Loss 1.313\n",
            "Epoch 42: Train Loss: 1.273\n",
            "Epoch 42: Test Accuracy: 89.41%\n",
            "Epoch 43, Batch 50: Loss 1.397\n",
            "Epoch 43, Batch 100: Loss 1.358\n",
            "Epoch 43, Batch 150: Loss 1.281\n",
            "Epoch 43: Train Loss: 1.323\n",
            "Epoch 43: Test Accuracy: 89.50%\n",
            "Epoch 44, Batch 50: Loss 1.179\n",
            "Epoch 44, Batch 100: Loss 1.229\n",
            "Epoch 44, Batch 150: Loss 1.278\n",
            "Epoch 44: Train Loss: 1.239\n",
            "Epoch 44: Test Accuracy: 85.79%\n",
            "Epoch 45, Batch 50: Loss 1.334\n",
            "Epoch 45, Batch 100: Loss 1.191\n",
            "Epoch 45, Batch 150: Loss 1.263\n",
            "Epoch 45: Train Loss: 1.263\n",
            "Epoch 45: Test Accuracy: 89.55%\n",
            "Model saved at epoch 45.\n",
            "Epoch 46, Batch 50: Loss 1.252\n",
            "Epoch 46, Batch 100: Loss 1.260\n",
            "Epoch 46, Batch 150: Loss 1.236\n",
            "Epoch 46: Train Loss: 1.271\n",
            "Epoch 46: Test Accuracy: 87.10%\n",
            "Epoch 47, Batch 50: Loss 1.308\n",
            "Epoch 47, Batch 100: Loss 1.266\n",
            "Epoch 47, Batch 150: Loss 1.295\n",
            "Epoch 47: Train Loss: 1.274\n",
            "Epoch 47: Test Accuracy: 90.15%\n",
            "Epoch 48, Batch 50: Loss 1.233\n",
            "Epoch 48, Batch 100: Loss 1.258\n",
            "Epoch 48, Batch 150: Loss 1.256\n",
            "Epoch 48: Train Loss: 1.246\n",
            "Epoch 48: Test Accuracy: 90.21%\n",
            "Epoch 49, Batch 50: Loss 1.288\n",
            "Epoch 49, Batch 100: Loss 1.192\n",
            "Epoch 49, Batch 150: Loss 1.305\n",
            "Epoch 49: Train Loss: 1.262\n",
            "Epoch 49: Test Accuracy: 90.34%\n",
            "Epoch 50, Batch 50: Loss 1.229\n",
            "Epoch 50, Batch 100: Loss 1.253\n",
            "Epoch 50, Batch 150: Loss 1.237\n",
            "Epoch 50: Train Loss: 1.251\n",
            "Epoch 50: Test Accuracy: 90.26%\n",
            "Model saved at epoch 50.\n",
            "Epoch 51, Batch 50: Loss 1.288\n",
            "Epoch 51, Batch 100: Loss 1.169\n",
            "Epoch 51, Batch 150: Loss 1.257\n",
            "Epoch 51: Train Loss: 1.204\n",
            "Epoch 51: Test Accuracy: 89.90%\n",
            "Epoch 52, Batch 50: Loss 1.249\n",
            "Epoch 52, Batch 100: Loss 1.203\n",
            "Epoch 52, Batch 150: Loss 1.312\n",
            "Epoch 52: Train Loss: 1.226\n",
            "Epoch 52: Test Accuracy: 89.28%\n",
            "Epoch 53, Batch 50: Loss 1.301\n",
            "Epoch 53, Batch 100: Loss 1.231\n",
            "Epoch 53, Batch 150: Loss 1.233\n",
            "Epoch 53: Train Loss: 1.260\n",
            "Epoch 53: Test Accuracy: 91.15%\n",
            "Epoch 54, Batch 50: Loss 1.278\n",
            "Epoch 54, Batch 100: Loss 1.182\n",
            "Epoch 54, Batch 150: Loss 1.203\n",
            "Epoch 54: Train Loss: 1.231\n",
            "Epoch 54: Test Accuracy: 89.51%\n",
            "Epoch 55, Batch 50: Loss 1.212\n",
            "Epoch 55, Batch 100: Loss 1.280\n",
            "Epoch 55, Batch 150: Loss 1.240\n",
            "Epoch 55: Train Loss: 1.244\n",
            "Epoch 55: Test Accuracy: 89.29%\n",
            "Model saved at epoch 55.\n",
            "Epoch 56, Batch 50: Loss 1.198\n",
            "Epoch 56, Batch 100: Loss 1.252\n",
            "Epoch 56, Batch 150: Loss 1.215\n",
            "Epoch 56: Train Loss: 1.205\n",
            "Epoch 56: Test Accuracy: 91.22%\n",
            "Epoch 57, Batch 50: Loss 1.227\n",
            "Epoch 57, Batch 100: Loss 1.162\n",
            "Epoch 57, Batch 150: Loss 1.288\n",
            "Epoch 57: Train Loss: 1.230\n",
            "Epoch 57: Test Accuracy: 89.82%\n",
            "Epoch 58, Batch 50: Loss 1.250\n",
            "Epoch 58, Batch 100: Loss 1.216\n",
            "Epoch 58, Batch 150: Loss 1.216\n",
            "Epoch 58: Train Loss: 1.229\n",
            "Epoch 58: Test Accuracy: 90.55%\n",
            "Epoch 59, Batch 50: Loss 1.225\n",
            "Epoch 59, Batch 100: Loss 1.196\n",
            "Epoch 59, Batch 150: Loss 1.208\n",
            "Epoch 59: Train Loss: 1.214\n",
            "Epoch 59: Test Accuracy: 91.26%\n",
            "Epoch 60, Batch 50: Loss 1.263\n",
            "Epoch 60, Batch 100: Loss 1.341\n",
            "Epoch 60, Batch 150: Loss 1.181\n",
            "Epoch 60: Train Loss: 1.225\n",
            "Epoch 60: Test Accuracy: 87.57%\n",
            "Model saved at epoch 60.\n",
            "Epoch 61, Batch 50: Loss 1.267\n",
            "Epoch 61, Batch 100: Loss 1.246\n",
            "Epoch 61, Batch 150: Loss 1.101\n",
            "Epoch 61: Train Loss: 1.217\n",
            "Epoch 61: Test Accuracy: 91.15%\n",
            "Epoch 62, Batch 50: Loss 1.146\n",
            "Epoch 62, Batch 100: Loss 1.203\n",
            "Epoch 62, Batch 150: Loss 1.218\n",
            "Epoch 62: Train Loss: 1.209\n",
            "Epoch 62: Test Accuracy: 91.12%\n",
            "Epoch 63, Batch 50: Loss 1.142\n",
            "Epoch 63, Batch 100: Loss 1.194\n",
            "Epoch 63, Batch 150: Loss 1.199\n",
            "Epoch 63: Train Loss: 1.188\n",
            "Epoch 63: Test Accuracy: 91.48%\n",
            "Epoch 64, Batch 50: Loss 1.232\n",
            "Epoch 64, Batch 100: Loss 1.226\n",
            "Epoch 64, Batch 150: Loss 1.190\n",
            "Epoch 64: Train Loss: 1.208\n",
            "Epoch 64: Test Accuracy: 88.95%\n",
            "Epoch 65, Batch 50: Loss 1.222\n",
            "Epoch 65, Batch 100: Loss 1.263\n",
            "Epoch 65, Batch 150: Loss 1.173\n",
            "Epoch 65: Train Loss: 1.205\n",
            "Epoch 65: Test Accuracy: 90.68%\n",
            "Model saved at epoch 65.\n",
            "Epoch 66, Batch 50: Loss 1.241\n",
            "Epoch 66, Batch 100: Loss 1.198\n",
            "Epoch 66, Batch 150: Loss 1.224\n",
            "Epoch 66: Train Loss: 1.221\n",
            "Epoch 66: Test Accuracy: 91.03%\n",
            "Epoch 67, Batch 50: Loss 1.189\n",
            "Epoch 67, Batch 100: Loss 1.215\n",
            "Epoch 67, Batch 150: Loss 1.177\n",
            "Epoch 67: Train Loss: 1.172\n",
            "Epoch 67: Test Accuracy: 91.87%\n",
            "Epoch 68, Batch 50: Loss 1.152\n",
            "Epoch 68, Batch 100: Loss 1.183\n",
            "Epoch 68, Batch 150: Loss 1.235\n",
            "Epoch 68: Train Loss: 1.196\n",
            "Epoch 68: Test Accuracy: 90.75%\n",
            "Epoch 69, Batch 50: Loss 1.187\n",
            "Epoch 69, Batch 100: Loss 1.134\n",
            "Epoch 69, Batch 150: Loss 1.190\n",
            "Epoch 69: Train Loss: 1.177\n",
            "Epoch 69: Test Accuracy: 91.82%\n",
            "Epoch 70, Batch 50: Loss 1.080\n",
            "Epoch 70, Batch 100: Loss 1.280\n",
            "Epoch 70, Batch 150: Loss 1.182\n",
            "Epoch 70: Train Loss: 1.182\n",
            "Epoch 70: Test Accuracy: 90.38%\n",
            "Model saved at epoch 70.\n",
            "Epoch 71, Batch 50: Loss 1.183\n",
            "Epoch 71, Batch 100: Loss 1.214\n",
            "Epoch 71, Batch 150: Loss 1.160\n",
            "Epoch 71: Train Loss: 1.194\n",
            "Epoch 71: Test Accuracy: 90.45%\n",
            "Epoch 72, Batch 50: Loss 1.269\n",
            "Epoch 72, Batch 100: Loss 1.206\n",
            "Epoch 72, Batch 150: Loss 1.169\n",
            "Epoch 72: Train Loss: 1.221\n",
            "Epoch 72: Test Accuracy: 91.58%\n",
            "Epoch 73, Batch 50: Loss 1.190\n",
            "Epoch 73, Batch 100: Loss 1.227\n",
            "Epoch 73, Batch 150: Loss 1.221\n",
            "Epoch 73: Train Loss: 1.205\n",
            "Epoch 73: Test Accuracy: 91.82%\n",
            "Epoch 74, Batch 50: Loss 1.250\n",
            "Epoch 74, Batch 100: Loss 1.209\n",
            "Epoch 74, Batch 150: Loss 1.188\n",
            "Epoch 74: Train Loss: 1.204\n",
            "Epoch 74: Test Accuracy: 91.30%\n",
            "Epoch 75, Batch 50: Loss 1.191\n",
            "Epoch 75, Batch 100: Loss 1.191\n",
            "Epoch 75, Batch 150: Loss 1.207\n",
            "Epoch 75: Train Loss: 1.202\n",
            "Epoch 75: Test Accuracy: 91.34%\n",
            "Model saved at epoch 75.\n",
            "Epoch 76, Batch 50: Loss 1.239\n",
            "Epoch 76, Batch 100: Loss 1.195\n",
            "Epoch 76, Batch 150: Loss 1.174\n",
            "Epoch 76: Train Loss: 1.207\n",
            "Epoch 76: Test Accuracy: 92.23%\n",
            "Epoch 77, Batch 50: Loss 1.084\n",
            "Epoch 77, Batch 100: Loss 1.200\n",
            "Epoch 77, Batch 150: Loss 1.203\n",
            "Epoch 77: Train Loss: 1.175\n",
            "Epoch 77: Test Accuracy: 90.55%\n",
            "Epoch 78, Batch 50: Loss 1.125\n",
            "Epoch 78, Batch 100: Loss 1.141\n",
            "Epoch 78, Batch 150: Loss 1.184\n",
            "Epoch 78: Train Loss: 1.158\n",
            "Epoch 78: Test Accuracy: 92.27%\n",
            "Epoch 79, Batch 50: Loss 1.237\n",
            "Epoch 79, Batch 100: Loss 1.164\n",
            "Epoch 79, Batch 150: Loss 1.205\n",
            "Epoch 79: Train Loss: 1.201\n",
            "Epoch 79: Test Accuracy: 91.81%\n",
            "Epoch 80, Batch 50: Loss 1.207\n",
            "Epoch 80, Batch 100: Loss 1.120\n",
            "Epoch 80, Batch 150: Loss 1.164\n",
            "Epoch 80: Train Loss: 1.192\n",
            "Epoch 80: Test Accuracy: 92.09%\n",
            "Model saved at epoch 80.\n",
            "Epoch 81, Batch 50: Loss 1.118\n",
            "Epoch 81, Batch 100: Loss 1.179\n",
            "Epoch 81, Batch 150: Loss 1.213\n",
            "Epoch 81: Train Loss: 1.174\n",
            "Epoch 81: Test Accuracy: 92.36%\n",
            "Epoch 82, Batch 50: Loss 1.186\n",
            "Epoch 82, Batch 100: Loss 1.187\n",
            "Epoch 82, Batch 150: Loss 1.209\n",
            "Epoch 82: Train Loss: 1.177\n",
            "Epoch 82: Test Accuracy: 92.07%\n",
            "Epoch 83, Batch 50: Loss 1.252\n",
            "Epoch 83, Batch 100: Loss 1.196\n",
            "Epoch 83, Batch 150: Loss 1.183\n",
            "Epoch 83: Train Loss: 1.188\n",
            "Epoch 83: Test Accuracy: 90.59%\n",
            "Epoch 84, Batch 50: Loss 1.153\n",
            "Epoch 84, Batch 100: Loss 1.151\n",
            "Epoch 84, Batch 150: Loss 1.191\n",
            "Epoch 84: Train Loss: 1.178\n",
            "Epoch 84: Test Accuracy: 92.37%\n",
            "Epoch 85, Batch 50: Loss 1.243\n",
            "Epoch 85, Batch 100: Loss 1.213\n",
            "Epoch 85, Batch 150: Loss 1.169\n",
            "Epoch 85: Train Loss: 1.198\n",
            "Epoch 85: Test Accuracy: 92.06%\n",
            "Model saved at epoch 85.\n",
            "Epoch 86, Batch 50: Loss 1.254\n",
            "Epoch 86, Batch 100: Loss 1.103\n",
            "Epoch 86, Batch 150: Loss 1.096\n",
            "Epoch 86: Train Loss: 1.163\n",
            "Epoch 86: Test Accuracy: 92.42%\n",
            "Epoch 87, Batch 50: Loss 1.085\n",
            "Epoch 87, Batch 100: Loss 1.124\n",
            "Epoch 87, Batch 150: Loss 1.178\n",
            "Epoch 87: Train Loss: 1.159\n",
            "Epoch 87: Test Accuracy: 92.68%\n",
            "Epoch 88, Batch 50: Loss 1.180\n",
            "Epoch 88, Batch 100: Loss 1.240\n",
            "Epoch 88, Batch 150: Loss 1.211\n",
            "Epoch 88: Train Loss: 1.211\n",
            "Epoch 88: Test Accuracy: 91.16%\n",
            "Epoch 89, Batch 50: Loss 1.154\n",
            "Epoch 89, Batch 100: Loss 1.202\n",
            "Epoch 89, Batch 150: Loss 1.075\n",
            "Epoch 89: Train Loss: 1.156\n",
            "Epoch 89: Test Accuracy: 92.03%\n",
            "Epoch 90, Batch 50: Loss 1.173\n",
            "Epoch 90, Batch 100: Loss 1.136\n",
            "Epoch 90, Batch 150: Loss 1.244\n",
            "Epoch 90: Train Loss: 1.207\n",
            "Epoch 90: Test Accuracy: 92.73%\n",
            "Model saved at epoch 90.\n",
            "Epoch 91, Batch 50: Loss 1.188\n",
            "Epoch 91, Batch 100: Loss 1.158\n",
            "Epoch 91, Batch 150: Loss 1.177\n",
            "Epoch 91: Train Loss: 1.182\n",
            "Epoch 91: Test Accuracy: 92.03%\n",
            "Epoch 92, Batch 50: Loss 1.158\n",
            "Epoch 92, Batch 100: Loss 1.190\n",
            "Epoch 92, Batch 150: Loss 1.061\n",
            "Epoch 92: Train Loss: 1.171\n",
            "Epoch 92: Test Accuracy: 92.33%\n",
            "Epoch 93, Batch 50: Loss 1.184\n",
            "Epoch 93, Batch 100: Loss 1.164\n",
            "Epoch 93, Batch 150: Loss 1.205\n",
            "Epoch 93: Train Loss: 1.200\n",
            "Epoch 93: Test Accuracy: 91.64%\n",
            "Epoch 94, Batch 50: Loss 1.151\n",
            "Epoch 94, Batch 100: Loss 1.200\n",
            "Epoch 94, Batch 150: Loss 1.139\n",
            "Epoch 94: Train Loss: 1.158\n",
            "Epoch 94: Test Accuracy: 90.16%\n",
            "Epoch 95, Batch 50: Loss 1.177\n",
            "Epoch 95, Batch 100: Loss 1.072\n",
            "Epoch 95, Batch 150: Loss 1.149\n",
            "Epoch 95: Train Loss: 1.145\n",
            "Epoch 95: Test Accuracy: 91.19%\n",
            "Model saved at epoch 95.\n",
            "Epoch 96, Batch 50: Loss 1.125\n",
            "Epoch 96, Batch 100: Loss 1.173\n",
            "Epoch 96, Batch 150: Loss 1.141\n",
            "Epoch 96: Train Loss: 1.157\n",
            "Epoch 96: Test Accuracy: 91.95%\n",
            "Epoch 97, Batch 50: Loss 1.226\n",
            "Epoch 97, Batch 100: Loss 1.158\n",
            "Epoch 97, Batch 150: Loss 1.206\n",
            "Epoch 97: Train Loss: 1.183\n",
            "Epoch 97: Test Accuracy: 91.82%\n",
            "Epoch 98, Batch 50: Loss 1.165\n",
            "Epoch 98, Batch 100: Loss 1.122\n",
            "Epoch 98, Batch 150: Loss 1.188\n",
            "Epoch 98: Train Loss: 1.179\n",
            "Epoch 98: Test Accuracy: 91.59%\n",
            "Epoch 99, Batch 50: Loss 1.182\n",
            "Epoch 99, Batch 100: Loss 1.162\n",
            "Epoch 99, Batch 150: Loss 1.206\n",
            "Epoch 99: Train Loss: 1.187\n",
            "Epoch 99: Test Accuracy: 90.14%\n",
            "Epoch 100, Batch 50: Loss 1.177\n",
            "Epoch 100, Batch 100: Loss 1.127\n",
            "Epoch 100, Batch 150: Loss 1.228\n",
            "Epoch 100: Train Loss: 1.172\n",
            "Epoch 100: Test Accuracy: 91.91%\n",
            "Model saved at epoch 100.\n",
            "Epoch 101, Batch 50: Loss 1.166\n",
            "Epoch 101, Batch 100: Loss 1.041\n",
            "Epoch 101, Batch 150: Loss 1.190\n",
            "Epoch 101: Train Loss: 1.133\n",
            "Epoch 101: Test Accuracy: 91.81%\n",
            "Epoch 102, Batch 50: Loss 1.210\n",
            "Epoch 102, Batch 100: Loss 1.079\n",
            "Epoch 102, Batch 150: Loss 1.150\n",
            "Epoch 102: Train Loss: 1.144\n",
            "Epoch 102: Test Accuracy: 89.31%\n",
            "Epoch 103, Batch 50: Loss 1.117\n",
            "Epoch 103, Batch 100: Loss 1.209\n",
            "Epoch 103, Batch 150: Loss 1.157\n",
            "Epoch 103: Train Loss: 1.163\n",
            "Epoch 103: Test Accuracy: 92.69%\n",
            "Epoch 104, Batch 50: Loss 1.218\n",
            "Epoch 104, Batch 100: Loss 1.270\n",
            "Epoch 104, Batch 150: Loss 1.234\n",
            "Epoch 104: Train Loss: 1.194\n",
            "Epoch 104: Test Accuracy: 91.47%\n",
            "Epoch 105, Batch 50: Loss 1.101\n",
            "Epoch 105, Batch 100: Loss 1.185\n",
            "Epoch 105, Batch 150: Loss 1.201\n",
            "Epoch 105: Train Loss: 1.160\n",
            "Epoch 105: Test Accuracy: 92.14%\n",
            "Model saved at epoch 105.\n",
            "Epoch 106, Batch 50: Loss 1.141\n",
            "Epoch 106, Batch 100: Loss 1.004\n",
            "Epoch 106, Batch 150: Loss 1.143\n",
            "Epoch 106: Train Loss: 1.120\n",
            "Epoch 106: Test Accuracy: 93.21%\n",
            "Epoch 107, Batch 50: Loss 1.187\n",
            "Epoch 107, Batch 100: Loss 1.118\n",
            "Epoch 107, Batch 150: Loss 1.128\n",
            "Epoch 107: Train Loss: 1.149\n",
            "Epoch 107: Test Accuracy: 92.49%\n",
            "Epoch 108, Batch 50: Loss 1.182\n",
            "Epoch 108, Batch 100: Loss 1.180\n",
            "Epoch 108, Batch 150: Loss 1.198\n",
            "Epoch 108: Train Loss: 1.159\n",
            "Epoch 108: Test Accuracy: 90.69%\n",
            "Epoch 109, Batch 50: Loss 1.154\n",
            "Epoch 109, Batch 100: Loss 1.169\n",
            "Epoch 109, Batch 150: Loss 1.174\n",
            "Epoch 109: Train Loss: 1.162\n",
            "Epoch 109: Test Accuracy: 92.78%\n",
            "Epoch 110, Batch 50: Loss 1.138\n",
            "Epoch 110, Batch 100: Loss 1.148\n",
            "Epoch 110, Batch 150: Loss 1.174\n",
            "Epoch 110: Train Loss: 1.142\n",
            "Epoch 110: Test Accuracy: 92.23%\n",
            "Model saved at epoch 110.\n",
            "Epoch 111, Batch 50: Loss 1.250\n",
            "Epoch 111, Batch 100: Loss 1.095\n",
            "Epoch 111, Batch 150: Loss 1.131\n",
            "Epoch 111: Train Loss: 1.153\n",
            "Epoch 111: Test Accuracy: 92.37%\n",
            "Epoch 112, Batch 50: Loss 1.158\n",
            "Epoch 112, Batch 100: Loss 1.190\n",
            "Epoch 112, Batch 150: Loss 1.247\n",
            "Epoch 112: Train Loss: 1.196\n",
            "Epoch 112: Test Accuracy: 91.41%\n",
            "Epoch 113, Batch 50: Loss 1.204\n",
            "Epoch 113, Batch 100: Loss 1.174\n",
            "Epoch 113, Batch 150: Loss 1.142\n",
            "Epoch 113: Train Loss: 1.182\n",
            "Epoch 113: Test Accuracy: 92.71%\n",
            "Epoch 114, Batch 50: Loss 1.168\n",
            "Epoch 114, Batch 100: Loss 1.216\n",
            "Epoch 114, Batch 150: Loss 1.106\n",
            "Epoch 114: Train Loss: 1.164\n",
            "Epoch 114: Test Accuracy: 91.75%\n",
            "Epoch 115, Batch 50: Loss 1.090\n",
            "Epoch 115, Batch 100: Loss 1.132\n",
            "Epoch 115, Batch 150: Loss 1.191\n",
            "Epoch 115: Train Loss: 1.152\n",
            "Epoch 115: Test Accuracy: 91.59%\n",
            "Model saved at epoch 115.\n",
            "Epoch 116, Batch 50: Loss 1.191\n",
            "Epoch 116, Batch 100: Loss 1.123\n",
            "Epoch 116, Batch 150: Loss 1.015\n",
            "Epoch 116: Train Loss: 1.115\n",
            "Epoch 116: Test Accuracy: 91.61%\n",
            "Epoch 117, Batch 50: Loss 1.171\n",
            "Epoch 117, Batch 100: Loss 1.108\n",
            "Epoch 117, Batch 150: Loss 1.131\n",
            "Epoch 117: Train Loss: 1.144\n",
            "Epoch 117: Test Accuracy: 93.36%\n",
            "Epoch 118, Batch 50: Loss 1.164\n",
            "Epoch 118, Batch 100: Loss 1.170\n",
            "Epoch 118, Batch 150: Loss 1.068\n",
            "Epoch 118: Train Loss: 1.134\n",
            "Epoch 118: Test Accuracy: 92.85%\n",
            "Epoch 119, Batch 50: Loss 1.181\n",
            "Epoch 119, Batch 100: Loss 1.207\n",
            "Epoch 119, Batch 150: Loss 1.146\n",
            "Epoch 119: Train Loss: 1.174\n",
            "Epoch 119: Test Accuracy: 93.25%\n",
            "Epoch 120, Batch 50: Loss 1.152\n",
            "Epoch 120, Batch 100: Loss 1.150\n",
            "Epoch 120, Batch 150: Loss 1.215\n",
            "Epoch 120: Train Loss: 1.165\n",
            "Epoch 120: Test Accuracy: 92.18%\n",
            "Model saved at epoch 120.\n",
            "Epoch 121, Batch 50: Loss 1.138\n",
            "Epoch 121, Batch 100: Loss 1.044\n",
            "Epoch 121, Batch 150: Loss 1.111\n",
            "Epoch 121: Train Loss: 1.109\n",
            "Epoch 121: Test Accuracy: 92.27%\n",
            "Epoch 122, Batch 50: Loss 1.171\n",
            "Epoch 122, Batch 100: Loss 1.190\n",
            "Epoch 122, Batch 150: Loss 1.111\n",
            "Epoch 122: Train Loss: 1.151\n",
            "Epoch 122: Test Accuracy: 93.49%\n",
            "Epoch 123, Batch 50: Loss 1.113\n",
            "Epoch 123, Batch 100: Loss 1.172\n",
            "Epoch 123, Batch 150: Loss 1.157\n",
            "Epoch 123: Train Loss: 1.162\n",
            "Epoch 123: Test Accuracy: 92.54%\n",
            "Epoch 124, Batch 50: Loss 1.107\n",
            "Epoch 124, Batch 100: Loss 1.145\n",
            "Epoch 124, Batch 150: Loss 1.227\n",
            "Epoch 124: Train Loss: 1.166\n",
            "Epoch 124: Test Accuracy: 93.01%\n",
            "Epoch 125, Batch 50: Loss 1.218\n",
            "Epoch 125, Batch 100: Loss 1.117\n",
            "Epoch 125, Batch 150: Loss 1.152\n",
            "Epoch 125: Train Loss: 1.148\n",
            "Epoch 125: Test Accuracy: 91.57%\n",
            "Model saved at epoch 125.\n",
            "Epoch 126, Batch 50: Loss 1.152\n",
            "Epoch 126, Batch 100: Loss 1.166\n",
            "Epoch 126, Batch 150: Loss 1.156\n",
            "Epoch 126: Train Loss: 1.152\n",
            "Epoch 126: Test Accuracy: 92.74%\n",
            "Epoch 127, Batch 50: Loss 1.082\n",
            "Epoch 127, Batch 100: Loss 1.142\n",
            "Epoch 127, Batch 150: Loss 1.138\n",
            "Epoch 127: Train Loss: 1.120\n",
            "Epoch 127: Test Accuracy: 93.17%\n",
            "Epoch 128, Batch 50: Loss 1.200\n",
            "Epoch 128, Batch 100: Loss 1.086\n",
            "Epoch 128, Batch 150: Loss 1.156\n",
            "Epoch 128: Train Loss: 1.155\n",
            "Epoch 128: Test Accuracy: 92.04%\n",
            "Epoch 129, Batch 50: Loss 1.059\n",
            "Epoch 129, Batch 100: Loss 1.113\n",
            "Epoch 129, Batch 150: Loss 1.158\n",
            "Epoch 129: Train Loss: 1.117\n",
            "Epoch 129: Test Accuracy: 93.15%\n",
            "Epoch 130, Batch 50: Loss 1.102\n",
            "Epoch 130, Batch 100: Loss 1.101\n",
            "Epoch 130, Batch 150: Loss 1.159\n",
            "Epoch 130: Train Loss: 1.139\n",
            "Epoch 130: Test Accuracy: 93.24%\n",
            "Model saved at epoch 130.\n",
            "Epoch 131, Batch 50: Loss 1.166\n",
            "Epoch 131, Batch 100: Loss 1.127\n",
            "Epoch 131, Batch 150: Loss 1.152\n",
            "Epoch 131: Train Loss: 1.146\n",
            "Epoch 131: Test Accuracy: 93.14%\n",
            "Epoch 132, Batch 50: Loss 1.095\n",
            "Epoch 132, Batch 100: Loss 1.086\n",
            "Epoch 132, Batch 150: Loss 1.106\n",
            "Epoch 132: Train Loss: 1.112\n",
            "Epoch 132: Test Accuracy: 92.98%\n",
            "Epoch 133, Batch 50: Loss 1.180\n",
            "Epoch 133, Batch 100: Loss 1.067\n",
            "Epoch 133, Batch 150: Loss 1.043\n",
            "Epoch 133: Train Loss: 1.099\n",
            "Epoch 133: Test Accuracy: 92.55%\n",
            "Epoch 134, Batch 50: Loss 1.166\n",
            "Epoch 134, Batch 100: Loss 1.142\n",
            "Epoch 134, Batch 150: Loss 1.167\n",
            "Epoch 134: Train Loss: 1.168\n",
            "Epoch 134: Test Accuracy: 93.67%\n",
            "Epoch 135, Batch 50: Loss 1.148\n",
            "Epoch 135, Batch 100: Loss 1.181\n",
            "Epoch 135, Batch 150: Loss 1.154\n",
            "Epoch 135: Train Loss: 1.151\n",
            "Epoch 135: Test Accuracy: 93.72%\n",
            "Model saved at epoch 135.\n",
            "Epoch 136, Batch 50: Loss 1.111\n",
            "Epoch 136, Batch 100: Loss 1.114\n",
            "Epoch 136, Batch 150: Loss 1.113\n",
            "Epoch 136: Train Loss: 1.091\n",
            "Epoch 136: Test Accuracy: 93.25%\n",
            "Epoch 137, Batch 50: Loss 1.140\n",
            "Epoch 137, Batch 100: Loss 1.076\n",
            "Epoch 137, Batch 150: Loss 1.124\n",
            "Epoch 137: Train Loss: 1.112\n",
            "Epoch 137: Test Accuracy: 91.87%\n",
            "Epoch 138, Batch 50: Loss 1.129\n",
            "Epoch 138, Batch 100: Loss 1.196\n",
            "Epoch 138, Batch 150: Loss 1.119\n",
            "Epoch 138: Train Loss: 1.130\n",
            "Epoch 138: Test Accuracy: 93.74%\n",
            "Epoch 139, Batch 50: Loss 1.112\n",
            "Epoch 139, Batch 100: Loss 1.167\n",
            "Epoch 139, Batch 150: Loss 1.174\n",
            "Epoch 139: Train Loss: 1.151\n",
            "Epoch 139: Test Accuracy: 93.15%\n",
            "Epoch 140, Batch 50: Loss 1.196\n",
            "Epoch 140, Batch 100: Loss 1.095\n",
            "Epoch 140, Batch 150: Loss 1.068\n",
            "Epoch 140: Train Loss: 1.111\n",
            "Epoch 140: Test Accuracy: 92.07%\n",
            "Model saved at epoch 140.\n",
            "Epoch 141, Batch 50: Loss 1.033\n",
            "Epoch 141, Batch 100: Loss 1.215\n",
            "Epoch 141, Batch 150: Loss 1.181\n",
            "Epoch 141: Train Loss: 1.153\n",
            "Epoch 141: Test Accuracy: 93.90%\n",
            "Epoch 142, Batch 50: Loss 1.135\n",
            "Epoch 142, Batch 100: Loss 1.105\n",
            "Epoch 142, Batch 150: Loss 1.217\n",
            "Epoch 142: Train Loss: 1.139\n",
            "Epoch 142: Test Accuracy: 91.40%\n",
            "Epoch 143, Batch 50: Loss 1.114\n",
            "Epoch 143, Batch 100: Loss 1.164\n",
            "Epoch 143, Batch 150: Loss 1.121\n",
            "Epoch 143: Train Loss: 1.113\n",
            "Epoch 143: Test Accuracy: 93.90%\n",
            "Epoch 144, Batch 50: Loss 1.059\n",
            "Epoch 144, Batch 100: Loss 1.140\n",
            "Epoch 144, Batch 150: Loss 1.194\n",
            "Epoch 144: Train Loss: 1.111\n",
            "Epoch 144: Test Accuracy: 93.77%\n",
            "Epoch 145, Batch 50: Loss 1.116\n",
            "Epoch 145, Batch 100: Loss 1.139\n",
            "Epoch 145, Batch 150: Loss 1.180\n",
            "Epoch 145: Train Loss: 1.134\n",
            "Epoch 145: Test Accuracy: 93.66%\n",
            "Model saved at epoch 145.\n",
            "Epoch 146, Batch 50: Loss 1.054\n",
            "Epoch 146, Batch 100: Loss 1.214\n",
            "Epoch 146, Batch 150: Loss 1.195\n",
            "Epoch 146: Train Loss: 1.143\n",
            "Epoch 146: Test Accuracy: 93.27%\n",
            "Epoch 147, Batch 50: Loss 1.076\n",
            "Epoch 147, Batch 100: Loss 1.083\n",
            "Epoch 147, Batch 150: Loss 1.141\n",
            "Epoch 147: Train Loss: 1.091\n",
            "Epoch 147: Test Accuracy: 92.90%\n",
            "Epoch 148, Batch 50: Loss 1.086\n",
            "Epoch 148, Batch 100: Loss 1.111\n",
            "Epoch 148, Batch 150: Loss 1.129\n",
            "Epoch 148: Train Loss: 1.099\n",
            "Epoch 148: Test Accuracy: 93.87%\n",
            "Epoch 149, Batch 50: Loss 1.168\n",
            "Epoch 149, Batch 100: Loss 1.066\n",
            "Epoch 149, Batch 150: Loss 1.123\n",
            "Epoch 149: Train Loss: 1.138\n",
            "Epoch 149: Test Accuracy: 93.60%\n",
            "Epoch 150, Batch 50: Loss 1.081\n",
            "Epoch 150, Batch 100: Loss 1.093\n",
            "Epoch 150, Batch 150: Loss 1.056\n",
            "Epoch 150: Train Loss: 1.090\n",
            "Epoch 150: Test Accuracy: 93.30%\n",
            "Model saved at epoch 150.\n",
            "Epoch 151, Batch 50: Loss 1.131\n",
            "Epoch 151, Batch 100: Loss 1.138\n",
            "Epoch 151, Batch 150: Loss 1.153\n",
            "Epoch 151: Train Loss: 1.139\n",
            "Epoch 151: Test Accuracy: 93.24%\n",
            "Epoch 152, Batch 50: Loss 1.164\n",
            "Epoch 152, Batch 100: Loss 1.204\n",
            "Epoch 152, Batch 150: Loss 1.141\n",
            "Epoch 152: Train Loss: 1.172\n",
            "Epoch 152: Test Accuracy: 94.19%\n",
            "Epoch 153, Batch 50: Loss 1.091\n",
            "Epoch 153, Batch 100: Loss 1.115\n",
            "Epoch 153, Batch 150: Loss 1.110\n",
            "Epoch 153: Train Loss: 1.110\n",
            "Epoch 153: Test Accuracy: 94.09%\n",
            "Epoch 154, Batch 50: Loss 1.136\n",
            "Epoch 154, Batch 100: Loss 1.081\n",
            "Epoch 154, Batch 150: Loss 1.077\n",
            "Epoch 154: Train Loss: 1.108\n",
            "Epoch 154: Test Accuracy: 92.94%\n",
            "Epoch 155, Batch 50: Loss 1.140\n",
            "Epoch 155, Batch 100: Loss 1.049\n",
            "Epoch 155, Batch 150: Loss 1.057\n",
            "Epoch 155: Train Loss: 1.072\n",
            "Epoch 155: Test Accuracy: 93.99%\n",
            "Model saved at epoch 155.\n",
            "Epoch 156, Batch 50: Loss 1.047\n",
            "Epoch 156, Batch 100: Loss 1.148\n",
            "Epoch 156, Batch 150: Loss 1.097\n",
            "Epoch 156: Train Loss: 1.092\n",
            "Epoch 156: Test Accuracy: 93.80%\n",
            "Epoch 157, Batch 50: Loss 1.047\n",
            "Epoch 157, Batch 100: Loss 1.095\n",
            "Epoch 157, Batch 150: Loss 1.140\n",
            "Epoch 157: Train Loss: 1.091\n",
            "Epoch 157: Test Accuracy: 93.94%\n",
            "Epoch 158, Batch 50: Loss 1.137\n",
            "Epoch 158, Batch 100: Loss 1.072\n",
            "Epoch 158, Batch 150: Loss 1.145\n",
            "Epoch 158: Train Loss: 1.118\n",
            "Epoch 158: Test Accuracy: 94.01%\n",
            "Epoch 159, Batch 50: Loss 1.093\n",
            "Epoch 159, Batch 100: Loss 1.067\n",
            "Epoch 159, Batch 150: Loss 1.140\n",
            "Epoch 159: Train Loss: 1.110\n",
            "Epoch 159: Test Accuracy: 93.97%\n",
            "Epoch 160, Batch 50: Loss 0.997\n",
            "Epoch 160, Batch 100: Loss 1.168\n",
            "Epoch 160, Batch 150: Loss 1.145\n",
            "Epoch 160: Train Loss: 1.090\n",
            "Epoch 160: Test Accuracy: 93.99%\n",
            "Model saved at epoch 160.\n",
            "Epoch 161, Batch 50: Loss 1.152\n",
            "Epoch 161, Batch 100: Loss 1.110\n",
            "Epoch 161, Batch 150: Loss 1.002\n",
            "Epoch 161: Train Loss: 1.082\n",
            "Epoch 161: Test Accuracy: 93.58%\n",
            "Epoch 162, Batch 50: Loss 1.110\n",
            "Epoch 162, Batch 100: Loss 1.111\n",
            "Epoch 162, Batch 150: Loss 1.050\n",
            "Epoch 162: Train Loss: 1.087\n",
            "Epoch 162: Test Accuracy: 94.38%\n",
            "Epoch 163, Batch 50: Loss 1.114\n",
            "Epoch 163, Batch 100: Loss 1.118\n",
            "Epoch 163, Batch 150: Loss 1.118\n",
            "Epoch 163: Train Loss: 1.101\n",
            "Epoch 163: Test Accuracy: 93.21%\n",
            "Epoch 164, Batch 50: Loss 1.139\n",
            "Epoch 164, Batch 100: Loss 1.151\n",
            "Epoch 164, Batch 150: Loss 1.031\n",
            "Epoch 164: Train Loss: 1.115\n",
            "Epoch 164: Test Accuracy: 92.87%\n",
            "Epoch 165, Batch 50: Loss 1.173\n",
            "Epoch 165, Batch 100: Loss 1.160\n",
            "Epoch 165, Batch 150: Loss 1.148\n",
            "Epoch 165: Train Loss: 1.137\n",
            "Epoch 165: Test Accuracy: 93.55%\n",
            "Model saved at epoch 165.\n",
            "Epoch 166, Batch 50: Loss 1.116\n",
            "Epoch 166, Batch 100: Loss 1.087\n",
            "Epoch 166, Batch 150: Loss 1.017\n",
            "Epoch 166: Train Loss: 1.070\n",
            "Epoch 166: Test Accuracy: 93.82%\n",
            "Epoch 167, Batch 50: Loss 1.087\n",
            "Epoch 167, Batch 100: Loss 1.029\n",
            "Epoch 167, Batch 150: Loss 1.094\n",
            "Epoch 167: Train Loss: 1.078\n",
            "Epoch 167: Test Accuracy: 94.00%\n",
            "Epoch 168, Batch 50: Loss 1.110\n",
            "Epoch 168, Batch 100: Loss 1.034\n",
            "Epoch 168, Batch 150: Loss 1.135\n",
            "Epoch 168: Train Loss: 1.092\n",
            "Epoch 168: Test Accuracy: 93.79%\n",
            "Epoch 169, Batch 50: Loss 1.073\n",
            "Epoch 169, Batch 100: Loss 1.089\n",
            "Epoch 169, Batch 150: Loss 1.057\n",
            "Epoch 169: Train Loss: 1.085\n",
            "Epoch 169: Test Accuracy: 93.89%\n",
            "Epoch 170, Batch 50: Loss 1.117\n",
            "Epoch 170, Batch 100: Loss 1.092\n",
            "Epoch 170, Batch 150: Loss 1.161\n",
            "Epoch 170: Train Loss: 1.123\n",
            "Epoch 170: Test Accuracy: 93.64%\n",
            "Model saved at epoch 170.\n",
            "Epoch 171, Batch 50: Loss 1.134\n",
            "Epoch 171, Batch 100: Loss 1.153\n",
            "Epoch 171, Batch 150: Loss 1.133\n",
            "Epoch 171: Train Loss: 1.125\n",
            "Epoch 171: Test Accuracy: 94.03%\n",
            "Epoch 172, Batch 50: Loss 0.958\n",
            "Epoch 172, Batch 100: Loss 1.020\n",
            "Epoch 172, Batch 150: Loss 1.135\n",
            "Epoch 172: Train Loss: 1.060\n",
            "Epoch 172: Test Accuracy: 94.23%\n",
            "Epoch 173, Batch 50: Loss 1.076\n",
            "Epoch 173, Batch 100: Loss 1.126\n",
            "Epoch 173, Batch 150: Loss 1.180\n",
            "Epoch 173: Train Loss: 1.094\n",
            "Epoch 173: Test Accuracy: 93.77%\n",
            "Epoch 174, Batch 50: Loss 1.051\n",
            "Epoch 174, Batch 100: Loss 1.113\n",
            "Epoch 174, Batch 150: Loss 1.064\n",
            "Epoch 174: Train Loss: 1.084\n",
            "Epoch 174: Test Accuracy: 94.08%\n",
            "Epoch 175, Batch 50: Loss 1.011\n",
            "Epoch 175, Batch 100: Loss 1.015\n",
            "Epoch 175, Batch 150: Loss 1.118\n",
            "Epoch 175: Train Loss: 1.058\n",
            "Epoch 175: Test Accuracy: 92.85%\n",
            "Model saved at epoch 175.\n",
            "Epoch 176, Batch 50: Loss 1.125\n",
            "Epoch 176, Batch 100: Loss 1.159\n",
            "Epoch 176, Batch 150: Loss 1.009\n",
            "Epoch 176: Train Loss: 1.116\n",
            "Epoch 176: Test Accuracy: 92.52%\n",
            "Epoch 177, Batch 50: Loss 1.107\n",
            "Epoch 177, Batch 100: Loss 1.073\n",
            "Epoch 177, Batch 150: Loss 1.047\n",
            "Epoch 177: Train Loss: 1.082\n",
            "Epoch 177: Test Accuracy: 93.43%\n",
            "Epoch 178, Batch 50: Loss 1.067\n",
            "Epoch 178, Batch 100: Loss 1.066\n",
            "Epoch 178, Batch 150: Loss 1.092\n",
            "Epoch 178: Train Loss: 1.075\n",
            "Epoch 178: Test Accuracy: 94.14%\n",
            "Epoch 179, Batch 50: Loss 1.184\n",
            "Epoch 179, Batch 100: Loss 1.036\n",
            "Epoch 179, Batch 150: Loss 1.085\n",
            "Epoch 179: Train Loss: 1.082\n",
            "Epoch 179: Test Accuracy: 93.93%\n",
            "Epoch 180, Batch 50: Loss 1.126\n",
            "Epoch 180, Batch 100: Loss 1.025\n",
            "Epoch 180, Batch 150: Loss 1.025\n",
            "Epoch 180: Train Loss: 1.076\n",
            "Epoch 180: Test Accuracy: 93.21%\n",
            "Model saved at epoch 180.\n",
            "Epoch 181, Batch 50: Loss 1.107\n",
            "Epoch 181, Batch 100: Loss 1.173\n",
            "Epoch 181, Batch 150: Loss 1.064\n",
            "Epoch 181: Train Loss: 1.097\n",
            "Epoch 181: Test Accuracy: 93.53%\n",
            "Epoch 182, Batch 50: Loss 1.087\n",
            "Epoch 182, Batch 100: Loss 1.021\n",
            "Epoch 182, Batch 150: Loss 1.062\n",
            "Epoch 182: Train Loss: 1.066\n",
            "Epoch 182: Test Accuracy: 93.56%\n",
            "Epoch 183, Batch 50: Loss 1.118\n",
            "Epoch 183, Batch 100: Loss 1.124\n",
            "Epoch 183, Batch 150: Loss 1.129\n",
            "Epoch 183: Train Loss: 1.115\n",
            "Epoch 183: Test Accuracy: 94.33%\n",
            "Epoch 184, Batch 50: Loss 1.176\n",
            "Epoch 184, Batch 100: Loss 1.096\n",
            "Epoch 184, Batch 150: Loss 1.025\n",
            "Epoch 184: Train Loss: 1.091\n",
            "Epoch 184: Test Accuracy: 93.66%\n",
            "Epoch 185, Batch 50: Loss 1.201\n",
            "Epoch 185, Batch 100: Loss 1.101\n",
            "Epoch 185, Batch 150: Loss 1.035\n",
            "Epoch 185: Train Loss: 1.108\n",
            "Epoch 185: Test Accuracy: 94.30%\n",
            "Model saved at epoch 185.\n",
            "Epoch 186, Batch 50: Loss 0.982\n",
            "Epoch 186, Batch 100: Loss 1.084\n",
            "Epoch 186, Batch 150: Loss 1.080\n",
            "Epoch 186: Train Loss: 1.046\n",
            "Epoch 186: Test Accuracy: 93.79%\n",
            "Epoch 187, Batch 50: Loss 1.134\n",
            "Epoch 187, Batch 100: Loss 1.030\n",
            "Epoch 187, Batch 150: Loss 1.086\n",
            "Epoch 187: Train Loss: 1.080\n",
            "Epoch 187: Test Accuracy: 94.27%\n",
            "Epoch 188, Batch 50: Loss 1.045\n",
            "Epoch 188, Batch 100: Loss 1.102\n",
            "Epoch 188, Batch 150: Loss 1.174\n",
            "Epoch 188: Train Loss: 1.110\n",
            "Epoch 188: Test Accuracy: 93.98%\n",
            "Epoch 189, Batch 50: Loss 1.060\n",
            "Epoch 189, Batch 100: Loss 1.081\n",
            "Epoch 189, Batch 150: Loss 1.172\n",
            "Epoch 189: Train Loss: 1.111\n",
            "Epoch 189: Test Accuracy: 94.32%\n",
            "Epoch 190, Batch 50: Loss 1.106\n",
            "Epoch 190, Batch 100: Loss 1.117\n",
            "Epoch 190, Batch 150: Loss 0.999\n",
            "Epoch 190: Train Loss: 1.073\n",
            "Epoch 190: Test Accuracy: 93.68%\n",
            "Model saved at epoch 190.\n",
            "Epoch 191, Batch 50: Loss 1.051\n",
            "Epoch 191, Batch 100: Loss 1.082\n",
            "Epoch 191, Batch 150: Loss 1.085\n",
            "Epoch 191: Train Loss: 1.075\n",
            "Epoch 191: Test Accuracy: 93.35%\n",
            "Epoch 192, Batch 50: Loss 1.106\n",
            "Epoch 192, Batch 100: Loss 1.052\n",
            "Epoch 192, Batch 150: Loss 1.089\n",
            "Epoch 192: Train Loss: 1.096\n",
            "Epoch 192: Test Accuracy: 94.09%\n",
            "Epoch 193, Batch 50: Loss 1.083\n",
            "Epoch 193, Batch 100: Loss 1.001\n",
            "Epoch 193, Batch 150: Loss 1.083\n",
            "Epoch 193: Train Loss: 1.067\n",
            "Epoch 193: Test Accuracy: 94.41%\n",
            "Epoch 194, Batch 50: Loss 1.046\n",
            "Epoch 194, Batch 100: Loss 1.043\n",
            "Epoch 194, Batch 150: Loss 1.137\n",
            "Epoch 194: Train Loss: 1.073\n",
            "Epoch 194: Test Accuracy: 93.97%\n",
            "Epoch 195, Batch 50: Loss 1.098\n",
            "Epoch 195, Batch 100: Loss 1.163\n",
            "Epoch 195, Batch 150: Loss 1.101\n",
            "Epoch 195: Train Loss: 1.112\n",
            "Epoch 195: Test Accuracy: 93.43%\n",
            "Model saved at epoch 195.\n",
            "Epoch 196, Batch 50: Loss 1.127\n",
            "Epoch 196, Batch 100: Loss 1.084\n",
            "Epoch 196, Batch 150: Loss 1.077\n",
            "Epoch 196: Train Loss: 1.083\n",
            "Epoch 196: Test Accuracy: 94.17%\n",
            "Epoch 197, Batch 50: Loss 1.034\n",
            "Epoch 197, Batch 100: Loss 1.116\n",
            "Epoch 197, Batch 150: Loss 1.085\n",
            "Epoch 197: Train Loss: 1.067\n",
            "Epoch 197: Test Accuracy: 93.86%\n",
            "Epoch 198, Batch 50: Loss 1.045\n",
            "Epoch 198, Batch 100: Loss 1.085\n",
            "Epoch 198, Batch 150: Loss 1.121\n",
            "Epoch 198: Train Loss: 1.078\n",
            "Epoch 198: Test Accuracy: 94.14%\n",
            "Epoch 199, Batch 50: Loss 1.151\n",
            "Epoch 199, Batch 100: Loss 1.000\n",
            "Epoch 199, Batch 150: Loss 1.071\n",
            "Epoch 199: Train Loss: 1.058\n",
            "Epoch 199: Test Accuracy: 94.43%\n",
            "Epoch 200, Batch 50: Loss 1.080\n",
            "Epoch 200, Batch 100: Loss 1.004\n",
            "Epoch 200, Batch 150: Loss 1.190\n",
            "Epoch 200: Train Loss: 1.101\n",
            "Epoch 200: Test Accuracy: 93.21%\n",
            "Model saved at epoch 200.\n",
            "Epoch 201, Batch 50: Loss 1.096\n",
            "Epoch 201, Batch 100: Loss 1.131\n",
            "Epoch 201, Batch 150: Loss 1.082\n",
            "Epoch 201: Train Loss: 1.094\n",
            "Epoch 201: Test Accuracy: 94.21%\n",
            "Epoch 202, Batch 50: Loss 1.047\n",
            "Epoch 202, Batch 100: Loss 1.105\n",
            "Epoch 202, Batch 150: Loss 1.054\n",
            "Epoch 202: Train Loss: 1.050\n",
            "Epoch 202: Test Accuracy: 94.18%\n",
            "Epoch 203, Batch 50: Loss 1.074\n",
            "Epoch 203, Batch 100: Loss 0.996\n",
            "Epoch 203, Batch 150: Loss 1.089\n",
            "Epoch 203: Train Loss: 1.040\n",
            "Epoch 203: Test Accuracy: 93.73%\n",
            "Epoch 204, Batch 50: Loss 1.105\n",
            "Epoch 204, Batch 100: Loss 1.052\n",
            "Epoch 204, Batch 150: Loss 1.091\n",
            "Epoch 204: Train Loss: 1.085\n",
            "Epoch 204: Test Accuracy: 94.73%\n",
            "Epoch 205, Batch 50: Loss 1.114\n",
            "Epoch 205, Batch 100: Loss 0.998\n",
            "Epoch 205, Batch 150: Loss 1.046\n",
            "Epoch 205: Train Loss: 1.045\n",
            "Epoch 205: Test Accuracy: 92.22%\n",
            "Model saved at epoch 205.\n",
            "Epoch 206, Batch 50: Loss 1.087\n",
            "Epoch 206, Batch 100: Loss 1.073\n",
            "Epoch 206, Batch 150: Loss 1.044\n",
            "Epoch 206: Train Loss: 1.059\n",
            "Epoch 206: Test Accuracy: 93.61%\n",
            "Epoch 207, Batch 50: Loss 1.063\n",
            "Epoch 207, Batch 100: Loss 1.076\n",
            "Epoch 207, Batch 150: Loss 1.086\n",
            "Epoch 207: Train Loss: 1.065\n",
            "Epoch 207: Test Accuracy: 94.31%\n",
            "Epoch 208, Batch 50: Loss 1.082\n",
            "Epoch 208, Batch 100: Loss 1.068\n",
            "Epoch 208, Batch 150: Loss 1.176\n",
            "Epoch 208: Train Loss: 1.080\n",
            "Epoch 208: Test Accuracy: 93.65%\n",
            "Epoch 209, Batch 50: Loss 1.059\n",
            "Epoch 209, Batch 100: Loss 1.033\n",
            "Epoch 209, Batch 150: Loss 1.054\n",
            "Epoch 209: Train Loss: 1.028\n",
            "Epoch 209: Test Accuracy: 93.98%\n",
            "Epoch 210, Batch 50: Loss 1.037\n",
            "Epoch 210, Batch 100: Loss 1.046\n",
            "Epoch 210, Batch 150: Loss 1.077\n",
            "Epoch 210: Train Loss: 1.086\n",
            "Epoch 210: Test Accuracy: 93.94%\n",
            "Model saved at epoch 210.\n",
            "Epoch 211, Batch 50: Loss 1.008\n",
            "Epoch 211, Batch 100: Loss 1.081\n",
            "Epoch 211, Batch 150: Loss 1.054\n",
            "Epoch 211: Train Loss: 1.043\n",
            "Epoch 211: Test Accuracy: 94.52%\n",
            "Epoch 212, Batch 50: Loss 1.091\n",
            "Epoch 212, Batch 100: Loss 1.100\n",
            "Epoch 212, Batch 150: Loss 1.060\n",
            "Epoch 212: Train Loss: 1.087\n",
            "Epoch 212: Test Accuracy: 94.95%\n",
            "Epoch 213, Batch 50: Loss 1.052\n",
            "Epoch 213, Batch 100: Loss 1.069\n",
            "Epoch 213, Batch 150: Loss 1.035\n",
            "Epoch 213: Train Loss: 1.049\n",
            "Epoch 213: Test Accuracy: 94.01%\n",
            "Epoch 214, Batch 50: Loss 0.979\n",
            "Epoch 214, Batch 100: Loss 1.027\n",
            "Epoch 214, Batch 150: Loss 1.142\n",
            "Epoch 214: Train Loss: 1.054\n",
            "Epoch 214: Test Accuracy: 94.63%\n",
            "Epoch 215, Batch 50: Loss 1.065\n",
            "Epoch 215, Batch 100: Loss 1.060\n",
            "Epoch 215, Batch 150: Loss 1.045\n",
            "Epoch 215: Train Loss: 1.056\n",
            "Epoch 215: Test Accuracy: 93.85%\n",
            "Model saved at epoch 215.\n",
            "Epoch 216, Batch 50: Loss 0.983\n",
            "Epoch 216, Batch 100: Loss 1.118\n",
            "Epoch 216, Batch 150: Loss 0.988\n",
            "Epoch 216: Train Loss: 1.022\n",
            "Epoch 216: Test Accuracy: 94.87%\n",
            "Epoch 217, Batch 50: Loss 1.086\n",
            "Epoch 217, Batch 100: Loss 1.060\n",
            "Epoch 217, Batch 150: Loss 1.071\n",
            "Epoch 217: Train Loss: 1.070\n",
            "Epoch 217: Test Accuracy: 94.62%\n",
            "Epoch 218, Batch 50: Loss 1.174\n",
            "Epoch 218, Batch 100: Loss 1.032\n",
            "Epoch 218, Batch 150: Loss 1.101\n",
            "Epoch 218: Train Loss: 1.106\n",
            "Epoch 218: Test Accuracy: 94.58%\n",
            "Epoch 219, Batch 50: Loss 1.069\n",
            "Epoch 219, Batch 100: Loss 1.043\n",
            "Epoch 219, Batch 150: Loss 1.047\n",
            "Epoch 219: Train Loss: 1.045\n",
            "Epoch 219: Test Accuracy: 94.62%\n",
            "Epoch 220, Batch 50: Loss 1.111\n",
            "Epoch 220, Batch 100: Loss 1.031\n",
            "Epoch 220, Batch 150: Loss 1.084\n",
            "Epoch 220: Train Loss: 1.071\n",
            "Epoch 220: Test Accuracy: 94.00%\n",
            "Model saved at epoch 220.\n",
            "Epoch 221, Batch 50: Loss 1.097\n",
            "Epoch 221, Batch 100: Loss 1.005\n",
            "Epoch 221, Batch 150: Loss 1.068\n",
            "Epoch 221: Train Loss: 1.058\n",
            "Epoch 221: Test Accuracy: 94.28%\n",
            "Epoch 222, Batch 50: Loss 1.146\n",
            "Epoch 222, Batch 100: Loss 0.990\n",
            "Epoch 222, Batch 150: Loss 1.052\n",
            "Epoch 222: Train Loss: 1.056\n",
            "Epoch 222: Test Accuracy: 94.19%\n",
            "Epoch 223, Batch 50: Loss 1.068\n",
            "Epoch 223, Batch 100: Loss 1.126\n",
            "Epoch 223, Batch 150: Loss 1.091\n",
            "Epoch 223: Train Loss: 1.076\n",
            "Epoch 223: Test Accuracy: 94.55%\n",
            "Epoch 224, Batch 50: Loss 1.018\n",
            "Epoch 224, Batch 100: Loss 1.052\n",
            "Epoch 224, Batch 150: Loss 1.113\n",
            "Epoch 224: Train Loss: 1.060\n",
            "Epoch 224: Test Accuracy: 94.14%\n",
            "Epoch 225, Batch 50: Loss 1.097\n",
            "Epoch 225, Batch 100: Loss 1.078\n",
            "Epoch 225, Batch 150: Loss 1.002\n",
            "Epoch 225: Train Loss: 1.077\n",
            "Epoch 225: Test Accuracy: 93.82%\n",
            "Model saved at epoch 225.\n",
            "Epoch 226, Batch 50: Loss 1.112\n",
            "Epoch 226, Batch 100: Loss 1.107\n",
            "Epoch 226, Batch 150: Loss 1.046\n",
            "Epoch 226: Train Loss: 1.078\n",
            "Epoch 226: Test Accuracy: 94.31%\n",
            "Epoch 227, Batch 50: Loss 1.055\n",
            "Epoch 227, Batch 100: Loss 1.077\n",
            "Epoch 227, Batch 150: Loss 1.062\n",
            "Epoch 227: Train Loss: 1.059\n",
            "Epoch 227: Test Accuracy: 94.79%\n",
            "Epoch 228, Batch 50: Loss 1.026\n",
            "Epoch 228, Batch 100: Loss 0.967\n",
            "Epoch 228, Batch 150: Loss 1.074\n",
            "Epoch 228: Train Loss: 1.009\n",
            "Epoch 228: Test Accuracy: 94.94%\n",
            "Epoch 229, Batch 50: Loss 1.105\n",
            "Epoch 229, Batch 100: Loss 1.036\n",
            "Epoch 229, Batch 150: Loss 1.019\n",
            "Epoch 229: Train Loss: 1.036\n",
            "Epoch 229: Test Accuracy: 94.78%\n",
            "Epoch 230, Batch 50: Loss 1.099\n",
            "Epoch 230, Batch 100: Loss 1.080\n",
            "Epoch 230, Batch 150: Loss 1.023\n",
            "Epoch 230: Train Loss: 1.038\n",
            "Epoch 230: Test Accuracy: 94.50%\n",
            "Model saved at epoch 230.\n",
            "Epoch 231, Batch 50: Loss 1.147\n",
            "Epoch 231, Batch 100: Loss 1.051\n",
            "Epoch 231, Batch 150: Loss 1.136\n",
            "Epoch 231: Train Loss: 1.117\n",
            "Epoch 231: Test Accuracy: 94.90%\n",
            "Epoch 232, Batch 50: Loss 1.054\n",
            "Epoch 232, Batch 100: Loss 0.978\n",
            "Epoch 232, Batch 150: Loss 1.056\n",
            "Epoch 232: Train Loss: 1.032\n",
            "Epoch 232: Test Accuracy: 94.32%\n",
            "Epoch 233, Batch 50: Loss 1.063\n",
            "Epoch 233, Batch 100: Loss 1.090\n",
            "Epoch 233, Batch 150: Loss 1.055\n",
            "Epoch 233: Train Loss: 1.077\n",
            "Epoch 233: Test Accuracy: 93.63%\n",
            "Epoch 234, Batch 50: Loss 1.057\n",
            "Epoch 234, Batch 100: Loss 1.116\n",
            "Epoch 234, Batch 150: Loss 1.005\n",
            "Epoch 234: Train Loss: 1.076\n",
            "Epoch 234: Test Accuracy: 94.59%\n",
            "Epoch 235, Batch 50: Loss 1.107\n",
            "Epoch 235, Batch 100: Loss 1.070\n",
            "Epoch 235, Batch 150: Loss 1.057\n",
            "Epoch 235: Train Loss: 1.081\n",
            "Epoch 235: Test Accuracy: 94.91%\n",
            "Model saved at epoch 235.\n",
            "Epoch 236, Batch 50: Loss 1.091\n",
            "Epoch 236, Batch 100: Loss 1.062\n",
            "Epoch 236, Batch 150: Loss 1.022\n",
            "Epoch 236: Train Loss: 1.053\n",
            "Epoch 236: Test Accuracy: 93.37%\n",
            "Epoch 237, Batch 50: Loss 1.083\n",
            "Epoch 237, Batch 100: Loss 1.059\n",
            "Epoch 237, Batch 150: Loss 1.043\n",
            "Epoch 237: Train Loss: 1.061\n",
            "Epoch 237: Test Accuracy: 94.83%\n",
            "Epoch 238, Batch 50: Loss 1.120\n",
            "Epoch 238, Batch 100: Loss 1.064\n",
            "Epoch 238, Batch 150: Loss 1.040\n",
            "Epoch 238: Train Loss: 1.068\n",
            "Epoch 238: Test Accuracy: 94.72%\n",
            "Epoch 239, Batch 50: Loss 1.053\n",
            "Epoch 239, Batch 100: Loss 1.032\n",
            "Epoch 239, Batch 150: Loss 1.100\n",
            "Epoch 239: Train Loss: 1.065\n",
            "Epoch 239: Test Accuracy: 94.67%\n",
            "Epoch 240, Batch 50: Loss 1.073\n",
            "Epoch 240, Batch 100: Loss 1.039\n",
            "Epoch 240, Batch 150: Loss 1.036\n",
            "Epoch 240: Train Loss: 1.053\n",
            "Epoch 240: Test Accuracy: 94.29%\n",
            "Model saved at epoch 240.\n",
            "Epoch 241, Batch 50: Loss 1.059\n",
            "Epoch 241, Batch 100: Loss 1.025\n",
            "Epoch 241, Batch 150: Loss 1.002\n",
            "Epoch 241: Train Loss: 1.029\n",
            "Epoch 241: Test Accuracy: 94.76%\n",
            "Epoch 242, Batch 50: Loss 1.072\n",
            "Epoch 242, Batch 100: Loss 1.063\n",
            "Epoch 242, Batch 150: Loss 1.090\n",
            "Epoch 242: Train Loss: 1.076\n",
            "Epoch 242: Test Accuracy: 94.94%\n",
            "Epoch 243, Batch 50: Loss 0.939\n",
            "Epoch 243, Batch 100: Loss 1.027\n",
            "Epoch 243, Batch 150: Loss 1.100\n",
            "Epoch 243: Train Loss: 1.045\n",
            "Epoch 243: Test Accuracy: 94.59%\n",
            "Epoch 244, Batch 50: Loss 1.049\n",
            "Epoch 244, Batch 100: Loss 1.063\n",
            "Epoch 244, Batch 150: Loss 1.039\n",
            "Epoch 244: Train Loss: 1.066\n",
            "Epoch 244: Test Accuracy: 94.62%\n",
            "Epoch 245, Batch 50: Loss 1.003\n",
            "Epoch 245, Batch 100: Loss 1.048\n",
            "Epoch 245, Batch 150: Loss 1.143\n",
            "Epoch 245: Train Loss: 1.072\n",
            "Epoch 245: Test Accuracy: 95.09%\n",
            "Model saved at epoch 245.\n",
            "Epoch 246, Batch 50: Loss 1.114\n",
            "Epoch 246, Batch 100: Loss 1.072\n",
            "Epoch 246, Batch 150: Loss 1.018\n",
            "Epoch 246: Train Loss: 1.065\n",
            "Epoch 246: Test Accuracy: 95.01%\n",
            "Epoch 247, Batch 50: Loss 1.059\n",
            "Epoch 247, Batch 100: Loss 1.061\n",
            "Epoch 247, Batch 150: Loss 0.954\n",
            "Epoch 247: Train Loss: 1.051\n",
            "Epoch 247: Test Accuracy: 95.02%\n",
            "Epoch 248, Batch 50: Loss 0.937\n",
            "Epoch 248, Batch 100: Loss 1.026\n",
            "Epoch 248, Batch 150: Loss 1.039\n",
            "Epoch 248: Train Loss: 1.007\n",
            "Epoch 248: Test Accuracy: 94.67%\n",
            "Epoch 249, Batch 50: Loss 0.984\n",
            "Epoch 249, Batch 100: Loss 1.066\n",
            "Epoch 249, Batch 150: Loss 1.019\n",
            "Epoch 249: Train Loss: 1.042\n",
            "Epoch 249: Test Accuracy: 94.68%\n",
            "Epoch 250, Batch 50: Loss 1.036\n",
            "Epoch 250, Batch 100: Loss 1.075\n",
            "Epoch 250, Batch 150: Loss 1.065\n",
            "Epoch 250: Train Loss: 1.075\n",
            "Epoch 250: Test Accuracy: 95.25%\n",
            "Model saved at epoch 250.\n",
            "Epoch 251, Batch 50: Loss 1.104\n",
            "Epoch 251, Batch 100: Loss 1.066\n",
            "Epoch 251, Batch 150: Loss 1.087\n",
            "Epoch 251: Train Loss: 1.085\n",
            "Epoch 251: Test Accuracy: 95.12%\n",
            "Epoch 252, Batch 50: Loss 1.050\n",
            "Epoch 252, Batch 100: Loss 1.000\n",
            "Epoch 252, Batch 150: Loss 1.025\n",
            "Epoch 252: Train Loss: 1.029\n",
            "Epoch 252: Test Accuracy: 94.38%\n",
            "Epoch 253, Batch 50: Loss 1.048\n",
            "Epoch 253, Batch 100: Loss 1.066\n",
            "Epoch 253, Batch 150: Loss 1.070\n",
            "Epoch 253: Train Loss: 1.047\n",
            "Epoch 253: Test Accuracy: 94.40%\n",
            "Epoch 254, Batch 50: Loss 1.045\n",
            "Epoch 254, Batch 100: Loss 1.040\n",
            "Epoch 254, Batch 150: Loss 1.030\n",
            "Epoch 254: Train Loss: 1.040\n",
            "Epoch 254: Test Accuracy: 94.59%\n",
            "Epoch 255, Batch 50: Loss 1.023\n",
            "Epoch 255, Batch 100: Loss 0.981\n",
            "Epoch 255, Batch 150: Loss 1.064\n",
            "Epoch 255: Train Loss: 1.038\n",
            "Epoch 255: Test Accuracy: 94.71%\n",
            "Model saved at epoch 255.\n",
            "Epoch 256, Batch 50: Loss 1.003\n",
            "Epoch 256, Batch 100: Loss 1.034\n",
            "Epoch 256, Batch 150: Loss 1.025\n",
            "Epoch 256: Train Loss: 1.013\n",
            "Epoch 256: Test Accuracy: 94.39%\n",
            "Epoch 257, Batch 50: Loss 1.096\n",
            "Epoch 257, Batch 100: Loss 1.052\n",
            "Epoch 257, Batch 150: Loss 1.052\n",
            "Epoch 257: Train Loss: 1.060\n",
            "Epoch 257: Test Accuracy: 94.65%\n",
            "Epoch 258, Batch 50: Loss 1.053\n",
            "Epoch 258, Batch 100: Loss 0.978\n",
            "Epoch 258, Batch 150: Loss 1.023\n",
            "Epoch 258: Train Loss: 1.028\n",
            "Epoch 258: Test Accuracy: 95.05%\n",
            "Epoch 259, Batch 50: Loss 1.031\n",
            "Epoch 259, Batch 100: Loss 1.030\n",
            "Epoch 259, Batch 150: Loss 1.019\n",
            "Epoch 259: Train Loss: 1.019\n",
            "Epoch 259: Test Accuracy: 95.06%\n",
            "Epoch 260, Batch 50: Loss 1.051\n",
            "Epoch 260, Batch 100: Loss 1.055\n",
            "Epoch 260, Batch 150: Loss 1.043\n",
            "Epoch 260: Train Loss: 1.033\n",
            "Epoch 260: Test Accuracy: 95.01%\n",
            "Model saved at epoch 260.\n",
            "Epoch 261, Batch 50: Loss 1.075\n",
            "Epoch 261, Batch 100: Loss 1.089\n",
            "Epoch 261, Batch 150: Loss 0.996\n",
            "Epoch 261: Train Loss: 1.048\n",
            "Epoch 261: Test Accuracy: 94.27%\n",
            "Epoch 262, Batch 50: Loss 1.012\n",
            "Epoch 262, Batch 100: Loss 1.005\n",
            "Epoch 262, Batch 150: Loss 1.064\n",
            "Epoch 262: Train Loss: 1.050\n",
            "Epoch 262: Test Accuracy: 94.98%\n",
            "Epoch 263, Batch 50: Loss 1.020\n",
            "Epoch 263, Batch 100: Loss 0.985\n",
            "Epoch 263, Batch 150: Loss 1.108\n",
            "Epoch 263: Train Loss: 1.027\n",
            "Epoch 263: Test Accuracy: 94.95%\n",
            "Epoch 264, Batch 50: Loss 1.055\n",
            "Epoch 264, Batch 100: Loss 1.003\n",
            "Epoch 264, Batch 150: Loss 1.008\n",
            "Epoch 264: Train Loss: 1.025\n",
            "Epoch 264: Test Accuracy: 95.12%\n",
            "Epoch 265, Batch 50: Loss 0.950\n",
            "Epoch 265, Batch 100: Loss 1.085\n",
            "Epoch 265, Batch 150: Loss 1.045\n",
            "Epoch 265: Train Loss: 1.015\n",
            "Epoch 265: Test Accuracy: 95.10%\n",
            "Model saved at epoch 265.\n",
            "Epoch 266, Batch 50: Loss 1.046\n",
            "Epoch 266, Batch 100: Loss 0.930\n",
            "Epoch 266, Batch 150: Loss 1.050\n",
            "Epoch 266: Train Loss: 1.026\n",
            "Epoch 266: Test Accuracy: 95.01%\n",
            "Epoch 267, Batch 50: Loss 1.005\n",
            "Epoch 267, Batch 100: Loss 1.011\n",
            "Epoch 267, Batch 150: Loss 1.026\n",
            "Epoch 267: Train Loss: 1.014\n",
            "Epoch 267: Test Accuracy: 95.28%\n",
            "Epoch 268, Batch 50: Loss 1.104\n",
            "Epoch 268, Batch 100: Loss 1.042\n",
            "Epoch 268, Batch 150: Loss 1.027\n",
            "Epoch 268: Train Loss: 1.029\n",
            "Epoch 268: Test Accuracy: 94.75%\n",
            "Epoch 269, Batch 50: Loss 1.087\n",
            "Epoch 269, Batch 100: Loss 1.116\n",
            "Epoch 269, Batch 150: Loss 1.083\n",
            "Epoch 269: Train Loss: 1.058\n",
            "Epoch 269: Test Accuracy: 95.34%\n",
            "Epoch 270, Batch 50: Loss 1.149\n",
            "Epoch 270, Batch 100: Loss 1.038\n",
            "Epoch 270, Batch 150: Loss 1.113\n",
            "Epoch 270: Train Loss: 1.093\n",
            "Epoch 270: Test Accuracy: 95.44%\n",
            "Model saved at epoch 270.\n",
            "Epoch 271, Batch 50: Loss 0.961\n",
            "Epoch 271, Batch 100: Loss 0.997\n",
            "Epoch 271, Batch 150: Loss 1.017\n",
            "Epoch 271: Train Loss: 1.013\n",
            "Epoch 271: Test Accuracy: 95.05%\n",
            "Epoch 272, Batch 50: Loss 1.052\n",
            "Epoch 272, Batch 100: Loss 1.051\n",
            "Epoch 272, Batch 150: Loss 1.078\n",
            "Epoch 272: Train Loss: 1.064\n",
            "Epoch 272: Test Accuracy: 95.05%\n",
            "Epoch 273, Batch 50: Loss 0.997\n",
            "Epoch 273, Batch 100: Loss 1.031\n",
            "Epoch 273, Batch 150: Loss 1.095\n",
            "Epoch 273: Train Loss: 1.021\n",
            "Epoch 273: Test Accuracy: 94.98%\n",
            "Epoch 274, Batch 50: Loss 1.042\n",
            "Epoch 274, Batch 100: Loss 0.987\n",
            "Epoch 274, Batch 150: Loss 1.068\n",
            "Epoch 274: Train Loss: 1.034\n",
            "Epoch 274: Test Accuracy: 95.19%\n",
            "Epoch 275, Batch 50: Loss 1.040\n",
            "Epoch 275, Batch 100: Loss 1.031\n",
            "Epoch 275, Batch 150: Loss 1.093\n",
            "Epoch 275: Train Loss: 1.029\n",
            "Epoch 275: Test Accuracy: 95.37%\n",
            "Model saved at epoch 275.\n",
            "Epoch 276, Batch 50: Loss 0.967\n",
            "Epoch 276, Batch 100: Loss 1.083\n",
            "Epoch 276, Batch 150: Loss 1.062\n",
            "Epoch 276: Train Loss: 1.038\n",
            "Epoch 276: Test Accuracy: 95.57%\n",
            "Epoch 277, Batch 50: Loss 1.001\n",
            "Epoch 277, Batch 100: Loss 1.042\n",
            "Epoch 277, Batch 150: Loss 0.996\n",
            "Epoch 277: Train Loss: 1.025\n",
            "Epoch 277: Test Accuracy: 95.23%\n",
            "Epoch 278, Batch 50: Loss 1.055\n",
            "Epoch 278, Batch 100: Loss 1.039\n",
            "Epoch 278, Batch 150: Loss 1.053\n",
            "Epoch 278: Train Loss: 1.060\n",
            "Epoch 278: Test Accuracy: 95.54%\n",
            "Epoch 279, Batch 50: Loss 1.077\n",
            "Epoch 279, Batch 100: Loss 0.950\n",
            "Epoch 279, Batch 150: Loss 1.006\n",
            "Epoch 279: Train Loss: 1.030\n",
            "Epoch 279: Test Accuracy: 94.52%\n",
            "Epoch 280, Batch 50: Loss 1.049\n",
            "Epoch 280, Batch 100: Loss 1.014\n",
            "Epoch 280, Batch 150: Loss 1.025\n",
            "Epoch 280: Train Loss: 1.023\n",
            "Epoch 280: Test Accuracy: 95.06%\n",
            "Model saved at epoch 280.\n",
            "Epoch 281, Batch 50: Loss 1.047\n",
            "Epoch 281, Batch 100: Loss 0.962\n",
            "Epoch 281, Batch 150: Loss 1.005\n",
            "Epoch 281: Train Loss: 1.014\n",
            "Epoch 281: Test Accuracy: 95.20%\n",
            "Epoch 282, Batch 50: Loss 0.999\n",
            "Epoch 282, Batch 100: Loss 0.964\n",
            "Epoch 282, Batch 150: Loss 1.057\n",
            "Epoch 282: Train Loss: 0.997\n",
            "Epoch 282: Test Accuracy: 95.38%\n",
            "Epoch 283, Batch 50: Loss 0.998\n",
            "Epoch 283, Batch 100: Loss 1.046\n",
            "Epoch 283, Batch 150: Loss 0.993\n",
            "Epoch 283: Train Loss: 1.028\n",
            "Epoch 283: Test Accuracy: 95.32%\n",
            "Epoch 284, Batch 50: Loss 0.957\n",
            "Epoch 284, Batch 100: Loss 1.003\n",
            "Epoch 284, Batch 150: Loss 0.968\n",
            "Epoch 284: Train Loss: 0.970\n",
            "Epoch 284: Test Accuracy: 94.48%\n",
            "Epoch 285, Batch 50: Loss 0.993\n",
            "Epoch 285, Batch 100: Loss 1.087\n",
            "Epoch 285, Batch 150: Loss 0.998\n",
            "Epoch 285: Train Loss: 1.025\n",
            "Epoch 285: Test Accuracy: 95.70%\n",
            "Model saved at epoch 285.\n",
            "Epoch 286, Batch 50: Loss 1.018\n",
            "Epoch 286, Batch 100: Loss 0.985\n",
            "Epoch 286, Batch 150: Loss 1.003\n",
            "Epoch 286: Train Loss: 1.016\n",
            "Epoch 286: Test Accuracy: 95.55%\n",
            "Epoch 287, Batch 50: Loss 1.037\n",
            "Epoch 287, Batch 100: Loss 1.025\n",
            "Epoch 287, Batch 150: Loss 0.990\n",
            "Epoch 287: Train Loss: 1.013\n",
            "Epoch 287: Test Accuracy: 95.74%\n",
            "Epoch 288, Batch 50: Loss 1.053\n",
            "Epoch 288, Batch 100: Loss 0.943\n",
            "Epoch 288, Batch 150: Loss 0.983\n",
            "Epoch 288: Train Loss: 0.985\n",
            "Epoch 288: Test Accuracy: 95.56%\n",
            "Epoch 289, Batch 50: Loss 0.992\n",
            "Epoch 289, Batch 100: Loss 1.027\n",
            "Epoch 289, Batch 150: Loss 0.927\n",
            "Epoch 289: Train Loss: 0.977\n",
            "Epoch 289: Test Accuracy: 95.83%\n",
            "Epoch 290, Batch 50: Loss 1.035\n",
            "Epoch 290, Batch 100: Loss 1.063\n",
            "Epoch 290, Batch 150: Loss 1.031\n",
            "Epoch 290: Train Loss: 1.042\n",
            "Epoch 290: Test Accuracy: 95.74%\n",
            "Model saved at epoch 290.\n",
            "Epoch 291, Batch 50: Loss 1.015\n",
            "Epoch 291, Batch 100: Loss 0.968\n",
            "Epoch 291, Batch 150: Loss 1.018\n",
            "Epoch 291: Train Loss: 1.020\n",
            "Epoch 291: Test Accuracy: 95.78%\n",
            "Epoch 292, Batch 50: Loss 1.030\n",
            "Epoch 292, Batch 100: Loss 1.030\n",
            "Epoch 292, Batch 150: Loss 1.051\n",
            "Epoch 292: Train Loss: 1.022\n",
            "Epoch 292: Test Accuracy: 95.12%\n",
            "Epoch 293, Batch 50: Loss 0.988\n",
            "Epoch 293, Batch 100: Loss 1.043\n",
            "Epoch 293, Batch 150: Loss 1.017\n",
            "Epoch 293: Train Loss: 1.007\n",
            "Epoch 293: Test Accuracy: 95.39%\n",
            "Epoch 294, Batch 50: Loss 1.038\n",
            "Epoch 294, Batch 100: Loss 1.001\n",
            "Epoch 294, Batch 150: Loss 1.016\n",
            "Epoch 294: Train Loss: 1.011\n",
            "Epoch 294: Test Accuracy: 95.58%\n",
            "Epoch 295, Batch 50: Loss 0.868\n",
            "Epoch 295, Batch 100: Loss 0.969\n",
            "Epoch 295, Batch 150: Loss 0.953\n",
            "Epoch 295: Train Loss: 0.947\n",
            "Epoch 295: Test Accuracy: 95.15%\n",
            "Model saved at epoch 295.\n",
            "Epoch 296, Batch 50: Loss 1.066\n",
            "Epoch 296, Batch 100: Loss 1.013\n",
            "Epoch 296, Batch 150: Loss 0.902\n",
            "Epoch 296: Train Loss: 0.997\n",
            "Epoch 296: Test Accuracy: 95.18%\n",
            "Epoch 297, Batch 50: Loss 0.931\n",
            "Epoch 297, Batch 100: Loss 0.954\n",
            "Epoch 297, Batch 150: Loss 1.093\n",
            "Epoch 297: Train Loss: 1.014\n",
            "Epoch 297: Test Accuracy: 95.56%\n",
            "Epoch 298, Batch 50: Loss 0.989\n",
            "Epoch 298, Batch 100: Loss 1.004\n",
            "Epoch 298, Batch 150: Loss 0.972\n",
            "Epoch 298: Train Loss: 0.988\n",
            "Epoch 298: Test Accuracy: 95.30%\n",
            "Epoch 299, Batch 50: Loss 1.031\n",
            "Epoch 299, Batch 100: Loss 0.967\n",
            "Epoch 299, Batch 150: Loss 1.003\n",
            "Epoch 299: Train Loss: 1.003\n",
            "Epoch 299: Test Accuracy: 95.18%\n",
            "Epoch 300, Batch 50: Loss 0.938\n",
            "Epoch 300, Batch 100: Loss 0.952\n",
            "Epoch 300, Batch 150: Loss 1.037\n",
            "Epoch 300: Train Loss: 0.971\n",
            "Epoch 300: Test Accuracy: 95.93%\n",
            "Model saved at epoch 300.\n",
            "Epoch 301, Batch 50: Loss 1.080\n",
            "Epoch 301, Batch 100: Loss 1.051\n",
            "Epoch 301, Batch 150: Loss 1.052\n",
            "Epoch 301: Train Loss: 1.035\n",
            "Epoch 301: Test Accuracy: 95.29%\n",
            "Epoch 302, Batch 50: Loss 1.043\n",
            "Epoch 302, Batch 100: Loss 0.954\n",
            "Epoch 302, Batch 150: Loss 1.032\n",
            "Epoch 302: Train Loss: 1.021\n",
            "Epoch 302: Test Accuracy: 95.74%\n",
            "Epoch 303, Batch 50: Loss 0.997\n",
            "Epoch 303, Batch 100: Loss 0.984\n",
            "Epoch 303, Batch 150: Loss 1.000\n",
            "Epoch 303: Train Loss: 0.965\n",
            "Epoch 303: Test Accuracy: 95.59%\n",
            "Epoch 304, Batch 50: Loss 1.062\n",
            "Epoch 304, Batch 100: Loss 0.960\n",
            "Epoch 304, Batch 150: Loss 0.989\n",
            "Epoch 304: Train Loss: 1.006\n",
            "Epoch 304: Test Accuracy: 95.71%\n",
            "Epoch 305, Batch 50: Loss 0.963\n",
            "Epoch 305, Batch 100: Loss 0.994\n",
            "Epoch 305, Batch 150: Loss 0.984\n",
            "Epoch 305: Train Loss: 0.982\n",
            "Epoch 305: Test Accuracy: 95.62%\n",
            "Model saved at epoch 305.\n",
            "Epoch 306, Batch 50: Loss 0.970\n",
            "Epoch 306, Batch 100: Loss 1.028\n",
            "Epoch 306, Batch 150: Loss 0.950\n",
            "Epoch 306: Train Loss: 0.978\n",
            "Epoch 306: Test Accuracy: 95.17%\n",
            "Epoch 307, Batch 50: Loss 0.937\n",
            "Epoch 307, Batch 100: Loss 1.013\n",
            "Epoch 307, Batch 150: Loss 0.960\n",
            "Epoch 307: Train Loss: 0.993\n",
            "Epoch 307: Test Accuracy: 95.95%\n",
            "Epoch 308, Batch 50: Loss 1.016\n",
            "Epoch 308, Batch 100: Loss 0.957\n",
            "Epoch 308, Batch 150: Loss 1.055\n",
            "Epoch 308: Train Loss: 1.012\n",
            "Epoch 308: Test Accuracy: 95.67%\n",
            "Epoch 309, Batch 50: Loss 0.964\n",
            "Epoch 309, Batch 100: Loss 1.080\n",
            "Epoch 309, Batch 150: Loss 1.075\n",
            "Epoch 309: Train Loss: 1.032\n",
            "Epoch 309: Test Accuracy: 95.82%\n",
            "Epoch 310, Batch 50: Loss 0.982\n",
            "Epoch 310, Batch 100: Loss 0.934\n",
            "Epoch 310, Batch 150: Loss 1.011\n",
            "Epoch 310: Train Loss: 0.979\n",
            "Epoch 310: Test Accuracy: 95.60%\n",
            "Model saved at epoch 310.\n",
            "Epoch 311, Batch 50: Loss 1.073\n",
            "Epoch 311, Batch 100: Loss 1.016\n",
            "Epoch 311, Batch 150: Loss 0.911\n",
            "Epoch 311: Train Loss: 1.019\n",
            "Epoch 311: Test Accuracy: 95.70%\n",
            "Epoch 312, Batch 50: Loss 1.010\n",
            "Epoch 312, Batch 100: Loss 1.048\n",
            "Epoch 312, Batch 150: Loss 1.028\n",
            "Epoch 312: Train Loss: 1.031\n",
            "Epoch 312: Test Accuracy: 95.42%\n",
            "Epoch 313, Batch 50: Loss 1.004\n",
            "Epoch 313, Batch 100: Loss 0.956\n",
            "Epoch 313, Batch 150: Loss 0.968\n",
            "Epoch 313: Train Loss: 0.969\n",
            "Epoch 313: Test Accuracy: 95.67%\n",
            "Epoch 314, Batch 50: Loss 0.932\n",
            "Epoch 314, Batch 100: Loss 0.972\n",
            "Epoch 314, Batch 150: Loss 1.015\n",
            "Epoch 314: Train Loss: 0.968\n",
            "Epoch 314: Test Accuracy: 95.99%\n",
            "Epoch 315, Batch 50: Loss 0.971\n",
            "Epoch 315, Batch 100: Loss 1.023\n",
            "Epoch 315, Batch 150: Loss 1.058\n",
            "Epoch 315: Train Loss: 1.015\n",
            "Epoch 315: Test Accuracy: 95.62%\n",
            "Model saved at epoch 315.\n",
            "Epoch 316, Batch 50: Loss 0.962\n",
            "Epoch 316, Batch 100: Loss 0.997\n",
            "Epoch 316, Batch 150: Loss 0.979\n",
            "Epoch 316: Train Loss: 0.991\n",
            "Epoch 316: Test Accuracy: 95.16%\n",
            "Epoch 317, Batch 50: Loss 0.958\n",
            "Epoch 317, Batch 100: Loss 1.026\n",
            "Epoch 317, Batch 150: Loss 0.926\n",
            "Epoch 317: Train Loss: 0.976\n",
            "Epoch 317: Test Accuracy: 95.62%\n",
            "Epoch 318, Batch 50: Loss 1.035\n",
            "Epoch 318, Batch 100: Loss 1.049\n",
            "Epoch 318, Batch 150: Loss 1.009\n",
            "Epoch 318: Train Loss: 1.022\n",
            "Epoch 318: Test Accuracy: 95.70%\n",
            "Epoch 319, Batch 50: Loss 1.072\n",
            "Epoch 319, Batch 100: Loss 1.030\n",
            "Epoch 319, Batch 150: Loss 0.991\n",
            "Epoch 319: Train Loss: 1.022\n",
            "Epoch 319: Test Accuracy: 95.84%\n",
            "Epoch 320, Batch 50: Loss 0.987\n",
            "Epoch 320, Batch 100: Loss 1.033\n",
            "Epoch 320, Batch 150: Loss 0.953\n",
            "Epoch 320: Train Loss: 0.993\n",
            "Epoch 320: Test Accuracy: 95.44%\n",
            "Model saved at epoch 320.\n",
            "Epoch 321, Batch 50: Loss 1.047\n",
            "Epoch 321, Batch 100: Loss 0.865\n",
            "Epoch 321, Batch 150: Loss 0.949\n",
            "Epoch 321: Train Loss: 0.958\n",
            "Epoch 321: Test Accuracy: 95.82%\n",
            "Epoch 322, Batch 50: Loss 1.012\n",
            "Epoch 322, Batch 100: Loss 1.059\n",
            "Epoch 322, Batch 150: Loss 1.015\n",
            "Epoch 322: Train Loss: 1.000\n",
            "Epoch 322: Test Accuracy: 95.55%\n",
            "Epoch 323, Batch 50: Loss 1.009\n",
            "Epoch 323, Batch 100: Loss 0.975\n",
            "Epoch 323, Batch 150: Loss 0.929\n",
            "Epoch 323: Train Loss: 0.970\n",
            "Epoch 323: Test Accuracy: 95.54%\n",
            "Epoch 324, Batch 50: Loss 0.905\n",
            "Epoch 324, Batch 100: Loss 0.981\n",
            "Epoch 324, Batch 150: Loss 1.001\n",
            "Epoch 324: Train Loss: 0.975\n",
            "Epoch 324: Test Accuracy: 96.01%\n",
            "Epoch 325, Batch 50: Loss 1.047\n",
            "Epoch 325, Batch 100: Loss 1.061\n",
            "Epoch 325, Batch 150: Loss 1.022\n",
            "Epoch 325: Train Loss: 1.025\n",
            "Epoch 325: Test Accuracy: 95.82%\n",
            "Model saved at epoch 325.\n",
            "Epoch 326, Batch 50: Loss 0.984\n",
            "Epoch 326, Batch 100: Loss 1.007\n",
            "Epoch 326, Batch 150: Loss 0.979\n",
            "Epoch 326: Train Loss: 1.004\n",
            "Epoch 326: Test Accuracy: 95.38%\n",
            "Epoch 327, Batch 50: Loss 0.929\n",
            "Epoch 327, Batch 100: Loss 1.019\n",
            "Epoch 327, Batch 150: Loss 0.955\n",
            "Epoch 327: Train Loss: 0.949\n",
            "Epoch 327: Test Accuracy: 96.43%\n",
            "Epoch 328, Batch 50: Loss 0.934\n",
            "Epoch 328, Batch 100: Loss 1.004\n",
            "Epoch 328, Batch 150: Loss 0.969\n",
            "Epoch 328: Train Loss: 0.986\n",
            "Epoch 328: Test Accuracy: 95.83%\n",
            "Epoch 329, Batch 50: Loss 0.974\n",
            "Epoch 329, Batch 100: Loss 0.946\n",
            "Epoch 329, Batch 150: Loss 0.953\n",
            "Epoch 329: Train Loss: 0.976\n",
            "Epoch 329: Test Accuracy: 95.83%\n",
            "Epoch 330, Batch 50: Loss 0.987\n",
            "Epoch 330, Batch 100: Loss 0.984\n",
            "Epoch 330, Batch 150: Loss 0.930\n",
            "Epoch 330: Train Loss: 0.976\n",
            "Epoch 330: Test Accuracy: 96.33%\n",
            "Model saved at epoch 330.\n",
            "Epoch 331, Batch 50: Loss 0.974\n",
            "Epoch 331, Batch 100: Loss 0.943\n",
            "Epoch 331, Batch 150: Loss 0.969\n",
            "Epoch 331: Train Loss: 0.968\n",
            "Epoch 331: Test Accuracy: 96.07%\n",
            "Epoch 332, Batch 50: Loss 1.041\n",
            "Epoch 332, Batch 100: Loss 1.004\n",
            "Epoch 332, Batch 150: Loss 0.944\n",
            "Epoch 332: Train Loss: 0.984\n",
            "Epoch 332: Test Accuracy: 96.00%\n",
            "Epoch 333, Batch 50: Loss 0.932\n",
            "Epoch 333, Batch 100: Loss 0.982\n",
            "Epoch 333, Batch 150: Loss 1.031\n",
            "Epoch 333: Train Loss: 0.980\n",
            "Epoch 333: Test Accuracy: 95.89%\n",
            "Epoch 334, Batch 50: Loss 1.035\n",
            "Epoch 334, Batch 100: Loss 0.965\n",
            "Epoch 334, Batch 150: Loss 0.995\n",
            "Epoch 334: Train Loss: 0.987\n",
            "Epoch 334: Test Accuracy: 96.09%\n",
            "Epoch 335, Batch 50: Loss 0.990\n",
            "Epoch 335, Batch 100: Loss 1.000\n",
            "Epoch 335, Batch 150: Loss 0.942\n",
            "Epoch 335: Train Loss: 0.974\n",
            "Epoch 335: Test Accuracy: 96.17%\n",
            "Model saved at epoch 335.\n",
            "Epoch 336, Batch 50: Loss 0.924\n",
            "Epoch 336, Batch 100: Loss 0.967\n",
            "Epoch 336, Batch 150: Loss 1.023\n",
            "Epoch 336: Train Loss: 0.977\n",
            "Epoch 336: Test Accuracy: 96.06%\n",
            "Epoch 337, Batch 50: Loss 1.058\n",
            "Epoch 337, Batch 100: Loss 1.020\n",
            "Epoch 337, Batch 150: Loss 0.949\n",
            "Epoch 337: Train Loss: 0.998\n",
            "Epoch 337: Test Accuracy: 95.71%\n",
            "Epoch 338, Batch 50: Loss 0.910\n",
            "Epoch 338, Batch 100: Loss 0.990\n",
            "Epoch 338, Batch 150: Loss 0.941\n",
            "Epoch 338: Train Loss: 0.941\n",
            "Epoch 338: Test Accuracy: 95.72%\n",
            "Epoch 339, Batch 50: Loss 0.943\n",
            "Epoch 339, Batch 100: Loss 0.964\n",
            "Epoch 339, Batch 150: Loss 0.979\n",
            "Epoch 339: Train Loss: 0.929\n",
            "Epoch 339: Test Accuracy: 96.08%\n",
            "Epoch 340, Batch 50: Loss 0.973\n",
            "Epoch 340, Batch 100: Loss 1.052\n",
            "Epoch 340, Batch 150: Loss 0.976\n",
            "Epoch 340: Train Loss: 0.997\n",
            "Epoch 340: Test Accuracy: 95.87%\n",
            "Model saved at epoch 340.\n",
            "Epoch 341, Batch 50: Loss 1.018\n",
            "Epoch 341, Batch 100: Loss 1.001\n",
            "Epoch 341, Batch 150: Loss 0.954\n",
            "Epoch 341: Train Loss: 0.999\n",
            "Epoch 341: Test Accuracy: 96.40%\n",
            "Epoch 342, Batch 50: Loss 1.021\n",
            "Epoch 342, Batch 100: Loss 0.930\n",
            "Epoch 342, Batch 150: Loss 0.991\n",
            "Epoch 342: Train Loss: 0.975\n",
            "Epoch 342: Test Accuracy: 96.21%\n",
            "Epoch 343, Batch 50: Loss 0.899\n",
            "Epoch 343, Batch 100: Loss 0.935\n",
            "Epoch 343, Batch 150: Loss 1.000\n",
            "Epoch 343: Train Loss: 0.931\n",
            "Epoch 343: Test Accuracy: 96.15%\n",
            "Epoch 344, Batch 50: Loss 0.982\n",
            "Epoch 344, Batch 100: Loss 1.042\n",
            "Epoch 344, Batch 150: Loss 0.959\n",
            "Epoch 344: Train Loss: 1.001\n",
            "Epoch 344: Test Accuracy: 96.04%\n",
            "Epoch 345, Batch 50: Loss 0.989\n",
            "Epoch 345, Batch 100: Loss 1.009\n",
            "Epoch 345, Batch 150: Loss 0.961\n",
            "Epoch 345: Train Loss: 0.992\n",
            "Epoch 345: Test Accuracy: 96.18%\n",
            "Model saved at epoch 345.\n",
            "Epoch 346, Batch 50: Loss 0.974\n",
            "Epoch 346, Batch 100: Loss 0.954\n",
            "Epoch 346, Batch 150: Loss 0.995\n",
            "Epoch 346: Train Loss: 0.977\n",
            "Epoch 346: Test Accuracy: 96.11%\n",
            "Epoch 347, Batch 50: Loss 0.936\n",
            "Epoch 347, Batch 100: Loss 0.988\n",
            "Epoch 347, Batch 150: Loss 1.013\n",
            "Epoch 347: Train Loss: 0.953\n",
            "Epoch 347: Test Accuracy: 95.66%\n",
            "Epoch 348, Batch 50: Loss 0.950\n",
            "Epoch 348, Batch 100: Loss 1.044\n",
            "Epoch 348, Batch 150: Loss 1.051\n",
            "Epoch 348: Train Loss: 1.005\n",
            "Epoch 348: Test Accuracy: 96.19%\n",
            "Epoch 349, Batch 50: Loss 0.919\n",
            "Epoch 349, Batch 100: Loss 0.979\n",
            "Epoch 349, Batch 150: Loss 1.034\n",
            "Epoch 349: Train Loss: 0.977\n",
            "Epoch 349: Test Accuracy: 95.88%\n",
            "Epoch 350, Batch 50: Loss 0.920\n",
            "Epoch 350, Batch 100: Loss 0.993\n",
            "Epoch 350, Batch 150: Loss 0.987\n",
            "Epoch 350: Train Loss: 0.965\n",
            "Epoch 350: Test Accuracy: 95.92%\n",
            "Model saved at epoch 350.\n",
            "Epoch 351, Batch 50: Loss 1.000\n",
            "Epoch 351, Batch 100: Loss 0.959\n",
            "Epoch 351, Batch 150: Loss 0.963\n",
            "Epoch 351: Train Loss: 0.971\n",
            "Epoch 351: Test Accuracy: 96.27%\n",
            "Epoch 352, Batch 50: Loss 0.995\n",
            "Epoch 352, Batch 100: Loss 0.908\n",
            "Epoch 352, Batch 150: Loss 0.897\n",
            "Epoch 352: Train Loss: 0.960\n",
            "Epoch 352: Test Accuracy: 95.75%\n",
            "Epoch 353, Batch 50: Loss 0.955\n",
            "Epoch 353, Batch 100: Loss 1.000\n",
            "Epoch 353, Batch 150: Loss 0.915\n",
            "Epoch 353: Train Loss: 0.951\n",
            "Epoch 353: Test Accuracy: 96.24%\n",
            "Epoch 354, Batch 50: Loss 0.961\n",
            "Epoch 354, Batch 100: Loss 0.992\n",
            "Epoch 354, Batch 150: Loss 0.972\n",
            "Epoch 354: Train Loss: 0.981\n",
            "Epoch 354: Test Accuracy: 96.13%\n",
            "Epoch 355, Batch 50: Loss 0.932\n",
            "Epoch 355, Batch 100: Loss 0.954\n",
            "Epoch 355, Batch 150: Loss 1.007\n",
            "Epoch 355: Train Loss: 0.950\n",
            "Epoch 355: Test Accuracy: 95.94%\n",
            "Model saved at epoch 355.\n",
            "Epoch 356, Batch 50: Loss 0.956\n",
            "Epoch 356, Batch 100: Loss 0.968\n",
            "Epoch 356, Batch 150: Loss 1.000\n",
            "Epoch 356: Train Loss: 0.969\n",
            "Epoch 356: Test Accuracy: 96.15%\n",
            "Epoch 357, Batch 50: Loss 0.973\n",
            "Epoch 357, Batch 100: Loss 0.989\n",
            "Epoch 357, Batch 150: Loss 0.934\n",
            "Epoch 357: Train Loss: 0.941\n",
            "Epoch 357: Test Accuracy: 96.29%\n",
            "Epoch 358, Batch 50: Loss 1.003\n",
            "Epoch 358, Batch 100: Loss 1.016\n",
            "Epoch 358, Batch 150: Loss 1.008\n",
            "Epoch 358: Train Loss: 0.989\n",
            "Epoch 358: Test Accuracy: 95.93%\n",
            "Epoch 359, Batch 50: Loss 0.924\n",
            "Epoch 359, Batch 100: Loss 0.901\n",
            "Epoch 359, Batch 150: Loss 0.940\n",
            "Epoch 359: Train Loss: 0.930\n",
            "Epoch 359: Test Accuracy: 96.28%\n",
            "Epoch 360, Batch 50: Loss 0.942\n",
            "Epoch 360, Batch 100: Loss 0.870\n",
            "Epoch 360, Batch 150: Loss 0.963\n",
            "Epoch 360: Train Loss: 0.935\n",
            "Epoch 360: Test Accuracy: 96.26%\n",
            "Model saved at epoch 360.\n",
            "Epoch 361, Batch 50: Loss 0.916\n",
            "Epoch 361, Batch 100: Loss 0.879\n",
            "Epoch 361, Batch 150: Loss 0.902\n",
            "Epoch 361: Train Loss: 0.913\n",
            "Epoch 361: Test Accuracy: 96.44%\n",
            "Epoch 362, Batch 50: Loss 0.966\n",
            "Epoch 362, Batch 100: Loss 0.997\n",
            "Epoch 362, Batch 150: Loss 0.978\n",
            "Epoch 362: Train Loss: 0.958\n",
            "Epoch 362: Test Accuracy: 96.24%\n",
            "Epoch 363, Batch 50: Loss 0.952\n",
            "Epoch 363, Batch 100: Loss 0.953\n",
            "Epoch 363, Batch 150: Loss 0.967\n",
            "Epoch 363: Train Loss: 0.934\n",
            "Epoch 363: Test Accuracy: 96.52%\n",
            "Epoch 364, Batch 50: Loss 0.960\n",
            "Epoch 364, Batch 100: Loss 0.962\n",
            "Epoch 364, Batch 150: Loss 0.839\n",
            "Epoch 364: Train Loss: 0.924\n",
            "Epoch 364: Test Accuracy: 96.38%\n",
            "Epoch 365, Batch 50: Loss 0.943\n",
            "Epoch 365, Batch 100: Loss 0.973\n",
            "Epoch 365, Batch 150: Loss 0.951\n",
            "Epoch 365: Train Loss: 0.968\n",
            "Epoch 365: Test Accuracy: 96.52%\n",
            "Model saved at epoch 365.\n",
            "Epoch 366, Batch 50: Loss 0.989\n",
            "Epoch 366, Batch 100: Loss 0.968\n",
            "Epoch 366, Batch 150: Loss 0.922\n",
            "Epoch 366: Train Loss: 0.964\n",
            "Epoch 366: Test Accuracy: 96.44%\n",
            "Epoch 367, Batch 50: Loss 0.925\n",
            "Epoch 367, Batch 100: Loss 0.987\n",
            "Epoch 367, Batch 150: Loss 0.906\n",
            "Epoch 367: Train Loss: 0.950\n",
            "Epoch 367: Test Accuracy: 96.45%\n",
            "Epoch 368, Batch 50: Loss 0.957\n",
            "Epoch 368, Batch 100: Loss 0.913\n",
            "Epoch 368, Batch 150: Loss 0.857\n",
            "Epoch 368: Train Loss: 0.920\n",
            "Epoch 368: Test Accuracy: 95.99%\n",
            "Epoch 369, Batch 50: Loss 0.928\n",
            "Epoch 369, Batch 100: Loss 0.985\n",
            "Epoch 369, Batch 150: Loss 0.968\n",
            "Epoch 369: Train Loss: 0.959\n",
            "Epoch 369: Test Accuracy: 96.26%\n",
            "Epoch 370, Batch 50: Loss 0.969\n",
            "Epoch 370, Batch 100: Loss 0.933\n",
            "Epoch 370, Batch 150: Loss 0.911\n",
            "Epoch 370: Train Loss: 0.953\n",
            "Epoch 370: Test Accuracy: 96.26%\n",
            "Model saved at epoch 370.\n",
            "Epoch 371, Batch 50: Loss 0.951\n",
            "Epoch 371, Batch 100: Loss 0.895\n",
            "Epoch 371, Batch 150: Loss 0.923\n",
            "Epoch 371: Train Loss: 0.930\n",
            "Epoch 371: Test Accuracy: 96.43%\n",
            "Epoch 372, Batch 50: Loss 0.982\n",
            "Epoch 372, Batch 100: Loss 1.003\n",
            "Epoch 372, Batch 150: Loss 0.932\n",
            "Epoch 372: Train Loss: 0.969\n",
            "Epoch 372: Test Accuracy: 96.36%\n",
            "Epoch 373, Batch 50: Loss 0.930\n",
            "Epoch 373, Batch 100: Loss 0.988\n",
            "Epoch 373, Batch 150: Loss 0.999\n",
            "Epoch 373: Train Loss: 0.958\n",
            "Epoch 373: Test Accuracy: 96.21%\n",
            "Epoch 374, Batch 50: Loss 0.890\n",
            "Epoch 374, Batch 100: Loss 0.993\n",
            "Epoch 374, Batch 150: Loss 0.934\n",
            "Epoch 374: Train Loss: 0.938\n",
            "Epoch 374: Test Accuracy: 96.19%\n",
            "Epoch 375, Batch 50: Loss 0.930\n",
            "Epoch 375, Batch 100: Loss 0.997\n",
            "Epoch 375, Batch 150: Loss 0.949\n",
            "Epoch 375: Train Loss: 0.943\n",
            "Epoch 375: Test Accuracy: 96.32%\n",
            "Model saved at epoch 375.\n",
            "Epoch 376, Batch 50: Loss 0.890\n",
            "Epoch 376, Batch 100: Loss 0.978\n",
            "Epoch 376, Batch 150: Loss 0.962\n",
            "Epoch 376: Train Loss: 0.961\n",
            "Epoch 376: Test Accuracy: 96.27%\n",
            "Epoch 377, Batch 50: Loss 0.945\n",
            "Epoch 377, Batch 100: Loss 0.975\n",
            "Epoch 377, Batch 150: Loss 0.964\n",
            "Epoch 377: Train Loss: 0.963\n",
            "Epoch 377: Test Accuracy: 96.36%\n",
            "Epoch 378, Batch 50: Loss 0.966\n",
            "Epoch 378, Batch 100: Loss 0.988\n",
            "Epoch 378, Batch 150: Loss 0.959\n",
            "Epoch 378: Train Loss: 0.944\n",
            "Epoch 378: Test Accuracy: 96.32%\n",
            "Epoch 379, Batch 50: Loss 0.894\n",
            "Epoch 379, Batch 100: Loss 0.951\n",
            "Epoch 379, Batch 150: Loss 0.985\n",
            "Epoch 379: Train Loss: 0.964\n",
            "Epoch 379: Test Accuracy: 96.36%\n",
            "Epoch 380, Batch 50: Loss 0.913\n",
            "Epoch 380, Batch 100: Loss 0.941\n",
            "Epoch 380, Batch 150: Loss 0.953\n",
            "Epoch 380: Train Loss: 0.951\n",
            "Epoch 380: Test Accuracy: 96.46%\n",
            "Model saved at epoch 380.\n",
            "Epoch 381, Batch 50: Loss 0.939\n",
            "Epoch 381, Batch 100: Loss 0.916\n",
            "Epoch 381, Batch 150: Loss 0.909\n",
            "Epoch 381: Train Loss: 0.918\n",
            "Epoch 381: Test Accuracy: 96.26%\n",
            "Epoch 382, Batch 50: Loss 0.913\n",
            "Epoch 382, Batch 100: Loss 0.973\n",
            "Epoch 382, Batch 150: Loss 0.931\n",
            "Epoch 382: Train Loss: 0.918\n",
            "Epoch 382: Test Accuracy: 96.46%\n",
            "Epoch 383, Batch 50: Loss 0.923\n",
            "Epoch 383, Batch 100: Loss 0.935\n",
            "Epoch 383, Batch 150: Loss 0.912\n",
            "Epoch 383: Train Loss: 0.941\n",
            "Epoch 383: Test Accuracy: 96.30%\n",
            "Epoch 384, Batch 50: Loss 0.915\n",
            "Epoch 384, Batch 100: Loss 0.906\n",
            "Epoch 384, Batch 150: Loss 0.920\n",
            "Epoch 384: Train Loss: 0.920\n",
            "Epoch 384: Test Accuracy: 96.46%\n",
            "Epoch 385, Batch 50: Loss 0.987\n",
            "Epoch 385, Batch 100: Loss 0.923\n",
            "Epoch 385, Batch 150: Loss 0.871\n",
            "Epoch 385: Train Loss: 0.914\n",
            "Epoch 385: Test Accuracy: 96.46%\n",
            "Model saved at epoch 385.\n",
            "Epoch 386, Batch 50: Loss 0.923\n",
            "Epoch 386, Batch 100: Loss 0.957\n",
            "Epoch 386, Batch 150: Loss 0.958\n",
            "Epoch 386: Train Loss: 0.940\n",
            "Epoch 386: Test Accuracy: 96.55%\n",
            "Epoch 387, Batch 50: Loss 0.863\n",
            "Epoch 387, Batch 100: Loss 0.932\n",
            "Epoch 387, Batch 150: Loss 0.858\n",
            "Epoch 387: Train Loss: 0.892\n",
            "Epoch 387: Test Accuracy: 96.13%\n",
            "Epoch 388, Batch 50: Loss 0.907\n",
            "Epoch 388, Batch 100: Loss 0.901\n",
            "Epoch 388, Batch 150: Loss 0.951\n",
            "Epoch 388: Train Loss: 0.909\n",
            "Epoch 388: Test Accuracy: 96.47%\n",
            "Epoch 389, Batch 50: Loss 0.913\n",
            "Epoch 389, Batch 100: Loss 0.958\n",
            "Epoch 389, Batch 150: Loss 0.960\n",
            "Epoch 389: Train Loss: 0.927\n",
            "Epoch 389: Test Accuracy: 96.67%\n",
            "Epoch 390, Batch 50: Loss 0.910\n",
            "Epoch 390, Batch 100: Loss 0.834\n",
            "Epoch 390, Batch 150: Loss 0.931\n",
            "Epoch 390: Train Loss: 0.914\n",
            "Epoch 390: Test Accuracy: 96.49%\n",
            "Model saved at epoch 390.\n",
            "Epoch 391, Batch 50: Loss 0.934\n",
            "Epoch 391, Batch 100: Loss 0.930\n",
            "Epoch 391, Batch 150: Loss 1.015\n",
            "Epoch 391: Train Loss: 0.939\n",
            "Epoch 391: Test Accuracy: 96.14%\n",
            "Epoch 392, Batch 50: Loss 0.893\n",
            "Epoch 392, Batch 100: Loss 0.873\n",
            "Epoch 392, Batch 150: Loss 0.876\n",
            "Epoch 392: Train Loss: 0.889\n",
            "Epoch 392: Test Accuracy: 96.62%\n",
            "Epoch 393, Batch 50: Loss 0.952\n",
            "Epoch 393, Batch 100: Loss 0.980\n",
            "Epoch 393, Batch 150: Loss 0.980\n",
            "Epoch 393: Train Loss: 0.950\n",
            "Epoch 393: Test Accuracy: 96.54%\n",
            "Epoch 394, Batch 50: Loss 0.940\n",
            "Epoch 394, Batch 100: Loss 0.954\n",
            "Epoch 394, Batch 150: Loss 0.912\n",
            "Epoch 394: Train Loss: 0.947\n",
            "Epoch 394: Test Accuracy: 96.67%\n",
            "Epoch 395, Batch 50: Loss 0.920\n",
            "Epoch 395, Batch 100: Loss 0.988\n",
            "Epoch 395, Batch 150: Loss 0.993\n",
            "Epoch 395: Train Loss: 0.956\n",
            "Epoch 395: Test Accuracy: 96.58%\n",
            "Model saved at epoch 395.\n",
            "Epoch 396, Batch 50: Loss 0.858\n",
            "Epoch 396, Batch 100: Loss 0.931\n",
            "Epoch 396, Batch 150: Loss 0.946\n",
            "Epoch 396: Train Loss: 0.921\n",
            "Epoch 396: Test Accuracy: 96.49%\n",
            "Epoch 397, Batch 50: Loss 0.943\n",
            "Epoch 397, Batch 100: Loss 0.953\n",
            "Epoch 397, Batch 150: Loss 0.934\n",
            "Epoch 397: Train Loss: 0.924\n",
            "Epoch 397: Test Accuracy: 96.68%\n",
            "Epoch 398, Batch 50: Loss 0.917\n",
            "Epoch 398, Batch 100: Loss 0.910\n",
            "Epoch 398, Batch 150: Loss 0.918\n",
            "Epoch 398: Train Loss: 0.913\n",
            "Epoch 398: Test Accuracy: 96.89%\n",
            "Epoch 399, Batch 50: Loss 0.942\n",
            "Epoch 399, Batch 100: Loss 0.937\n",
            "Epoch 399, Batch 150: Loss 0.929\n",
            "Epoch 399: Train Loss: 0.921\n",
            "Epoch 399: Test Accuracy: 96.50%\n",
            "Epoch 400, Batch 50: Loss 0.947\n",
            "Epoch 400, Batch 100: Loss 0.878\n",
            "Epoch 400, Batch 150: Loss 0.890\n",
            "Epoch 400: Train Loss: 0.899\n",
            "Epoch 400: Test Accuracy: 96.76%\n",
            "Model saved at epoch 400.\n",
            "Epoch 401, Batch 50: Loss 0.870\n",
            "Epoch 401, Batch 100: Loss 0.975\n",
            "Epoch 401, Batch 150: Loss 0.915\n",
            "Epoch 401: Train Loss: 0.929\n",
            "Epoch 401: Test Accuracy: 96.69%\n",
            "Epoch 402, Batch 50: Loss 0.880\n",
            "Epoch 402, Batch 100: Loss 0.891\n",
            "Epoch 402, Batch 150: Loss 0.884\n",
            "Epoch 402: Train Loss: 0.904\n",
            "Epoch 402: Test Accuracy: 96.61%\n",
            "Epoch 403, Batch 50: Loss 0.899\n",
            "Epoch 403, Batch 100: Loss 0.982\n",
            "Epoch 403, Batch 150: Loss 0.964\n",
            "Epoch 403: Train Loss: 0.939\n",
            "Epoch 403: Test Accuracy: 96.81%\n",
            "Epoch 404, Batch 50: Loss 0.926\n",
            "Epoch 404, Batch 100: Loss 0.863\n",
            "Epoch 404, Batch 150: Loss 0.954\n",
            "Epoch 404: Train Loss: 0.913\n",
            "Epoch 404: Test Accuracy: 96.64%\n",
            "Epoch 405, Batch 50: Loss 0.928\n",
            "Epoch 405, Batch 100: Loss 0.868\n",
            "Epoch 405, Batch 150: Loss 0.920\n",
            "Epoch 405: Train Loss: 0.911\n",
            "Epoch 405: Test Accuracy: 96.51%\n",
            "Model saved at epoch 405.\n",
            "Epoch 406, Batch 50: Loss 0.999\n",
            "Epoch 406, Batch 100: Loss 0.935\n",
            "Epoch 406, Batch 150: Loss 0.964\n",
            "Epoch 406: Train Loss: 0.945\n",
            "Epoch 406: Test Accuracy: 96.85%\n",
            "Epoch 407, Batch 50: Loss 0.899\n",
            "Epoch 407, Batch 100: Loss 0.920\n",
            "Epoch 407, Batch 150: Loss 0.909\n",
            "Epoch 407: Train Loss: 0.907\n",
            "Epoch 407: Test Accuracy: 96.63%\n",
            "Epoch 408, Batch 50: Loss 0.900\n",
            "Epoch 408, Batch 100: Loss 0.905\n",
            "Epoch 408, Batch 150: Loss 0.973\n",
            "Epoch 408: Train Loss: 0.911\n",
            "Epoch 408: Test Accuracy: 96.85%\n",
            "Epoch 409, Batch 50: Loss 0.919\n",
            "Epoch 409, Batch 100: Loss 0.895\n",
            "Epoch 409, Batch 150: Loss 0.819\n",
            "Epoch 409: Train Loss: 0.883\n",
            "Epoch 409: Test Accuracy: 96.66%\n",
            "Epoch 410, Batch 50: Loss 0.869\n",
            "Epoch 410, Batch 100: Loss 0.884\n",
            "Epoch 410, Batch 150: Loss 0.901\n",
            "Epoch 410: Train Loss: 0.911\n",
            "Epoch 410: Test Accuracy: 96.72%\n",
            "Model saved at epoch 410.\n",
            "Epoch 411, Batch 50: Loss 0.965\n",
            "Epoch 411, Batch 100: Loss 0.971\n",
            "Epoch 411, Batch 150: Loss 0.917\n",
            "Epoch 411: Train Loss: 0.944\n",
            "Epoch 411: Test Accuracy: 96.81%\n",
            "Epoch 412, Batch 50: Loss 0.935\n",
            "Epoch 412, Batch 100: Loss 0.970\n",
            "Epoch 412, Batch 150: Loss 0.992\n",
            "Epoch 412: Train Loss: 0.940\n",
            "Epoch 412: Test Accuracy: 97.00%\n",
            "Epoch 413, Batch 50: Loss 0.892\n",
            "Epoch 413, Batch 100: Loss 0.883\n",
            "Epoch 413, Batch 150: Loss 0.876\n",
            "Epoch 413: Train Loss: 0.894\n",
            "Epoch 413: Test Accuracy: 96.78%\n",
            "Epoch 414, Batch 50: Loss 0.843\n",
            "Epoch 414, Batch 100: Loss 0.976\n",
            "Epoch 414, Batch 150: Loss 0.875\n",
            "Epoch 414: Train Loss: 0.917\n",
            "Epoch 414: Test Accuracy: 96.71%\n",
            "Epoch 415, Batch 50: Loss 0.896\n",
            "Epoch 415, Batch 100: Loss 0.932\n",
            "Epoch 415, Batch 150: Loss 0.916\n",
            "Epoch 415: Train Loss: 0.925\n",
            "Epoch 415: Test Accuracy: 96.81%\n",
            "Model saved at epoch 415.\n",
            "Epoch 416, Batch 50: Loss 0.919\n",
            "Epoch 416, Batch 100: Loss 0.991\n",
            "Epoch 416, Batch 150: Loss 0.908\n",
            "Epoch 416: Train Loss: 0.939\n",
            "Epoch 416: Test Accuracy: 96.79%\n",
            "Epoch 417, Batch 50: Loss 0.930\n",
            "Epoch 417, Batch 100: Loss 0.882\n",
            "Epoch 417, Batch 150: Loss 0.969\n",
            "Epoch 417: Train Loss: 0.916\n",
            "Epoch 417: Test Accuracy: 96.80%\n",
            "Epoch 418, Batch 50: Loss 0.937\n",
            "Epoch 418, Batch 100: Loss 0.893\n",
            "Epoch 418, Batch 150: Loss 0.886\n",
            "Epoch 418: Train Loss: 0.907\n",
            "Epoch 418: Test Accuracy: 96.76%\n",
            "Epoch 419, Batch 50: Loss 0.923\n",
            "Epoch 419, Batch 100: Loss 0.890\n",
            "Epoch 419, Batch 150: Loss 0.905\n",
            "Epoch 419: Train Loss: 0.925\n",
            "Epoch 419: Test Accuracy: 96.66%\n",
            "Epoch 420, Batch 50: Loss 0.843\n",
            "Epoch 420, Batch 100: Loss 0.799\n",
            "Epoch 420, Batch 150: Loss 0.883\n",
            "Epoch 420: Train Loss: 0.845\n",
            "Epoch 420: Test Accuracy: 96.90%\n",
            "Model saved at epoch 420.\n",
            "Epoch 421, Batch 50: Loss 0.925\n",
            "Epoch 421, Batch 100: Loss 0.958\n",
            "Epoch 421, Batch 150: Loss 0.857\n",
            "Epoch 421: Train Loss: 0.907\n",
            "Epoch 421: Test Accuracy: 96.74%\n",
            "Epoch 422, Batch 50: Loss 0.929\n",
            "Epoch 422, Batch 100: Loss 0.918\n",
            "Epoch 422, Batch 150: Loss 0.956\n",
            "Epoch 422: Train Loss: 0.925\n",
            "Epoch 422: Test Accuracy: 96.75%\n",
            "Epoch 423, Batch 50: Loss 0.984\n",
            "Epoch 423, Batch 100: Loss 0.889\n",
            "Epoch 423, Batch 150: Loss 0.915\n",
            "Epoch 423: Train Loss: 0.915\n",
            "Epoch 423: Test Accuracy: 96.82%\n",
            "Epoch 424, Batch 50: Loss 0.904\n",
            "Epoch 424, Batch 100: Loss 0.970\n",
            "Epoch 424, Batch 150: Loss 0.857\n",
            "Epoch 424: Train Loss: 0.926\n",
            "Epoch 424: Test Accuracy: 96.78%\n",
            "Epoch 425, Batch 50: Loss 0.798\n",
            "Epoch 425, Batch 100: Loss 0.820\n",
            "Epoch 425, Batch 150: Loss 0.926\n",
            "Epoch 425: Train Loss: 0.867\n",
            "Epoch 425: Test Accuracy: 96.83%\n",
            "Model saved at epoch 425.\n",
            "Epoch 426, Batch 50: Loss 0.852\n",
            "Epoch 426, Batch 100: Loss 0.909\n",
            "Epoch 426, Batch 150: Loss 0.882\n",
            "Epoch 426: Train Loss: 0.861\n",
            "Epoch 426: Test Accuracy: 96.95%\n",
            "Epoch 427, Batch 50: Loss 0.971\n",
            "Epoch 427, Batch 100: Loss 0.902\n",
            "Epoch 427, Batch 150: Loss 0.865\n",
            "Epoch 427: Train Loss: 0.921\n",
            "Epoch 427: Test Accuracy: 96.79%\n",
            "Epoch 428, Batch 50: Loss 0.856\n",
            "Epoch 428, Batch 100: Loss 0.871\n",
            "Epoch 428, Batch 150: Loss 0.951\n",
            "Epoch 428: Train Loss: 0.919\n",
            "Epoch 428: Test Accuracy: 96.80%\n",
            "Epoch 429, Batch 50: Loss 0.894\n",
            "Epoch 429, Batch 100: Loss 0.872\n",
            "Epoch 429, Batch 150: Loss 0.823\n",
            "Epoch 429: Train Loss: 0.886\n",
            "Epoch 429: Test Accuracy: 96.98%\n",
            "Epoch 430, Batch 50: Loss 0.887\n",
            "Epoch 430, Batch 100: Loss 1.004\n",
            "Epoch 430, Batch 150: Loss 0.852\n",
            "Epoch 430: Train Loss: 0.906\n",
            "Epoch 430: Test Accuracy: 96.89%\n",
            "Model saved at epoch 430.\n",
            "Epoch 431, Batch 50: Loss 0.839\n",
            "Epoch 431, Batch 100: Loss 0.921\n",
            "Epoch 431, Batch 150: Loss 0.892\n",
            "Epoch 431: Train Loss: 0.899\n",
            "Epoch 431: Test Accuracy: 96.84%\n",
            "Epoch 432, Batch 50: Loss 0.916\n",
            "Epoch 432, Batch 100: Loss 0.910\n",
            "Epoch 432, Batch 150: Loss 0.924\n",
            "Epoch 432: Train Loss: 0.926\n",
            "Epoch 432: Test Accuracy: 96.81%\n",
            "Epoch 433, Batch 50: Loss 0.879\n",
            "Epoch 433, Batch 100: Loss 0.893\n",
            "Epoch 433, Batch 150: Loss 0.912\n",
            "Epoch 433: Train Loss: 0.888\n",
            "Epoch 433: Test Accuracy: 96.99%\n",
            "Epoch 434, Batch 50: Loss 0.988\n",
            "Epoch 434, Batch 100: Loss 0.937\n",
            "Epoch 434, Batch 150: Loss 0.958\n",
            "Epoch 434: Train Loss: 0.952\n",
            "Epoch 434: Test Accuracy: 96.94%\n",
            "Epoch 435, Batch 50: Loss 0.880\n",
            "Epoch 435, Batch 100: Loss 0.879\n",
            "Epoch 435, Batch 150: Loss 0.866\n",
            "Epoch 435: Train Loss: 0.875\n",
            "Epoch 435: Test Accuracy: 96.86%\n",
            "Model saved at epoch 435.\n",
            "Epoch 436, Batch 50: Loss 0.864\n",
            "Epoch 436, Batch 100: Loss 0.878\n",
            "Epoch 436, Batch 150: Loss 0.913\n",
            "Epoch 436: Train Loss: 0.886\n",
            "Epoch 436: Test Accuracy: 96.72%\n",
            "Epoch 437, Batch 50: Loss 0.847\n",
            "Epoch 437, Batch 100: Loss 0.902\n",
            "Epoch 437, Batch 150: Loss 0.845\n",
            "Epoch 437: Train Loss: 0.872\n",
            "Epoch 437: Test Accuracy: 96.98%\n",
            "Epoch 438, Batch 50: Loss 0.902\n",
            "Epoch 438, Batch 100: Loss 0.883\n",
            "Epoch 438, Batch 150: Loss 0.941\n",
            "Epoch 438: Train Loss: 0.896\n",
            "Epoch 438: Test Accuracy: 96.98%\n",
            "Epoch 439, Batch 50: Loss 0.920\n",
            "Epoch 439, Batch 100: Loss 0.970\n",
            "Epoch 439, Batch 150: Loss 0.908\n",
            "Epoch 439: Train Loss: 0.924\n",
            "Epoch 439: Test Accuracy: 96.97%\n",
            "Epoch 440, Batch 50: Loss 0.856\n",
            "Epoch 440, Batch 100: Loss 0.919\n",
            "Epoch 440, Batch 150: Loss 0.851\n",
            "Epoch 440: Train Loss: 0.880\n",
            "Epoch 440: Test Accuracy: 96.96%\n",
            "Model saved at epoch 440.\n",
            "Epoch 441, Batch 50: Loss 0.921\n",
            "Epoch 441, Batch 100: Loss 0.930\n",
            "Epoch 441, Batch 150: Loss 0.863\n",
            "Epoch 441: Train Loss: 0.905\n",
            "Epoch 441: Test Accuracy: 96.94%\n",
            "Epoch 442, Batch 50: Loss 0.960\n",
            "Epoch 442, Batch 100: Loss 0.926\n",
            "Epoch 442, Batch 150: Loss 0.905\n",
            "Epoch 442: Train Loss: 0.922\n",
            "Epoch 442: Test Accuracy: 96.90%\n",
            "Epoch 443, Batch 50: Loss 0.880\n",
            "Epoch 443, Batch 100: Loss 0.830\n",
            "Epoch 443, Batch 150: Loss 0.902\n",
            "Epoch 443: Train Loss: 0.896\n",
            "Epoch 443: Test Accuracy: 96.96%\n",
            "Epoch 444, Batch 50: Loss 0.878\n",
            "Epoch 444, Batch 100: Loss 0.862\n",
            "Epoch 444, Batch 150: Loss 0.817\n",
            "Epoch 444: Train Loss: 0.862\n",
            "Epoch 444: Test Accuracy: 97.01%\n",
            "Epoch 445, Batch 50: Loss 0.853\n",
            "Epoch 445, Batch 100: Loss 0.827\n",
            "Epoch 445, Batch 150: Loss 0.905\n",
            "Epoch 445: Train Loss: 0.850\n",
            "Epoch 445: Test Accuracy: 96.99%\n",
            "Model saved at epoch 445.\n",
            "Epoch 446, Batch 50: Loss 0.863\n",
            "Epoch 446, Batch 100: Loss 0.844\n",
            "Epoch 446, Batch 150: Loss 0.917\n",
            "Epoch 446: Train Loss: 0.877\n",
            "Epoch 446: Test Accuracy: 96.91%\n",
            "Epoch 447, Batch 50: Loss 0.863\n",
            "Epoch 447, Batch 100: Loss 0.986\n",
            "Epoch 447, Batch 150: Loss 0.887\n",
            "Epoch 447: Train Loss: 0.899\n",
            "Epoch 447: Test Accuracy: 96.94%\n",
            "Epoch 448, Batch 50: Loss 0.836\n",
            "Epoch 448, Batch 100: Loss 0.888\n",
            "Epoch 448, Batch 150: Loss 0.960\n",
            "Epoch 448: Train Loss: 0.881\n",
            "Epoch 448: Test Accuracy: 96.95%\n",
            "Epoch 449, Batch 50: Loss 0.786\n",
            "Epoch 449, Batch 100: Loss 0.907\n",
            "Epoch 449, Batch 150: Loss 0.871\n",
            "Epoch 449: Train Loss: 0.845\n",
            "Epoch 449: Test Accuracy: 97.11%\n",
            "Epoch 450, Batch 50: Loss 0.883\n",
            "Epoch 450, Batch 100: Loss 0.827\n",
            "Epoch 450, Batch 150: Loss 0.892\n",
            "Epoch 450: Train Loss: 0.863\n",
            "Epoch 450: Test Accuracy: 97.07%\n",
            "Model saved at epoch 450.\n",
            "Epoch 451, Batch 50: Loss 0.846\n",
            "Epoch 451, Batch 100: Loss 0.906\n",
            "Epoch 451, Batch 150: Loss 0.865\n",
            "Epoch 451: Train Loss: 0.908\n",
            "Epoch 451: Test Accuracy: 96.97%\n",
            "Epoch 452, Batch 50: Loss 0.837\n",
            "Epoch 452, Batch 100: Loss 0.860\n",
            "Epoch 452, Batch 150: Loss 0.864\n",
            "Epoch 452: Train Loss: 0.873\n",
            "Epoch 452: Test Accuracy: 97.08%\n",
            "Epoch 453, Batch 50: Loss 0.955\n",
            "Epoch 453, Batch 100: Loss 0.844\n",
            "Epoch 453, Batch 150: Loss 0.892\n",
            "Epoch 453: Train Loss: 0.896\n",
            "Epoch 453: Test Accuracy: 96.99%\n",
            "Epoch 454, Batch 50: Loss 0.855\n",
            "Epoch 454, Batch 100: Loss 0.912\n",
            "Epoch 454, Batch 150: Loss 0.879\n",
            "Epoch 454: Train Loss: 0.889\n",
            "Epoch 454: Test Accuracy: 96.99%\n",
            "Epoch 455, Batch 50: Loss 0.893\n",
            "Epoch 455, Batch 100: Loss 0.809\n",
            "Epoch 455, Batch 150: Loss 0.784\n",
            "Epoch 455: Train Loss: 0.853\n",
            "Epoch 455: Test Accuracy: 96.96%\n",
            "Model saved at epoch 455.\n",
            "Epoch 456, Batch 50: Loss 0.796\n",
            "Epoch 456, Batch 100: Loss 0.899\n",
            "Epoch 456, Batch 150: Loss 0.843\n",
            "Epoch 456: Train Loss: 0.861\n",
            "Epoch 456: Test Accuracy: 97.03%\n",
            "Epoch 457, Batch 50: Loss 0.956\n",
            "Epoch 457, Batch 100: Loss 0.949\n",
            "Epoch 457, Batch 150: Loss 0.862\n",
            "Epoch 457: Train Loss: 0.913\n",
            "Epoch 457: Test Accuracy: 96.97%\n",
            "Epoch 458, Batch 50: Loss 0.912\n",
            "Epoch 458, Batch 100: Loss 0.904\n",
            "Epoch 458, Batch 150: Loss 0.838\n",
            "Epoch 458: Train Loss: 0.902\n",
            "Epoch 458: Test Accuracy: 96.97%\n",
            "Epoch 459, Batch 50: Loss 0.875\n",
            "Epoch 459, Batch 100: Loss 0.951\n",
            "Epoch 459, Batch 150: Loss 0.900\n",
            "Epoch 459: Train Loss: 0.870\n",
            "Epoch 459: Test Accuracy: 97.13%\n",
            "Epoch 460, Batch 50: Loss 0.816\n",
            "Epoch 460, Batch 100: Loss 0.881\n",
            "Epoch 460, Batch 150: Loss 0.863\n",
            "Epoch 460: Train Loss: 0.857\n",
            "Epoch 460: Test Accuracy: 97.05%\n",
            "Model saved at epoch 460.\n",
            "Epoch 461, Batch 50: Loss 0.840\n",
            "Epoch 461, Batch 100: Loss 0.858\n",
            "Epoch 461, Batch 150: Loss 0.857\n",
            "Epoch 461: Train Loss: 0.849\n",
            "Epoch 461: Test Accuracy: 97.13%\n",
            "Epoch 462, Batch 50: Loss 0.863\n",
            "Epoch 462, Batch 100: Loss 0.888\n",
            "Epoch 462, Batch 150: Loss 0.943\n",
            "Epoch 462: Train Loss: 0.881\n",
            "Epoch 462: Test Accuracy: 97.08%\n",
            "Epoch 463, Batch 50: Loss 0.877\n",
            "Epoch 463, Batch 100: Loss 0.861\n",
            "Epoch 463, Batch 150: Loss 0.815\n",
            "Epoch 463: Train Loss: 0.862\n",
            "Epoch 463: Test Accuracy: 97.02%\n",
            "Epoch 464, Batch 50: Loss 0.934\n",
            "Epoch 464, Batch 100: Loss 0.906\n",
            "Epoch 464, Batch 150: Loss 0.856\n",
            "Epoch 464: Train Loss: 0.904\n",
            "Epoch 464: Test Accuracy: 97.05%\n",
            "Epoch 465, Batch 50: Loss 0.889\n",
            "Epoch 465, Batch 100: Loss 0.885\n",
            "Epoch 465, Batch 150: Loss 0.861\n",
            "Epoch 465: Train Loss: 0.872\n",
            "Epoch 465: Test Accuracy: 96.92%\n",
            "Model saved at epoch 465.\n",
            "Epoch 466, Batch 50: Loss 0.874\n",
            "Epoch 466, Batch 100: Loss 0.920\n",
            "Epoch 466, Batch 150: Loss 0.970\n",
            "Epoch 466: Train Loss: 0.921\n",
            "Epoch 466: Test Accuracy: 97.12%\n",
            "Epoch 467, Batch 50: Loss 0.913\n",
            "Epoch 467, Batch 100: Loss 0.961\n",
            "Epoch 467, Batch 150: Loss 0.917\n",
            "Epoch 467: Train Loss: 0.924\n",
            "Epoch 467: Test Accuracy: 97.05%\n",
            "Epoch 468, Batch 50: Loss 0.944\n",
            "Epoch 468, Batch 100: Loss 0.813\n",
            "Epoch 468, Batch 150: Loss 0.892\n",
            "Epoch 468: Train Loss: 0.886\n",
            "Epoch 468: Test Accuracy: 96.96%\n",
            "Epoch 469, Batch 50: Loss 0.893\n",
            "Epoch 469, Batch 100: Loss 0.833\n",
            "Epoch 469, Batch 150: Loss 0.864\n",
            "Epoch 469: Train Loss: 0.876\n",
            "Epoch 469: Test Accuracy: 97.01%\n",
            "Epoch 470, Batch 50: Loss 0.840\n",
            "Epoch 470, Batch 100: Loss 0.833\n",
            "Epoch 470, Batch 150: Loss 0.857\n",
            "Epoch 470: Train Loss: 0.850\n",
            "Epoch 470: Test Accuracy: 97.07%\n",
            "Model saved at epoch 470.\n",
            "Epoch 471, Batch 50: Loss 0.813\n",
            "Epoch 471, Batch 100: Loss 0.926\n",
            "Epoch 471, Batch 150: Loss 0.927\n",
            "Epoch 471: Train Loss: 0.890\n",
            "Epoch 471: Test Accuracy: 97.00%\n",
            "Epoch 472, Batch 50: Loss 0.823\n",
            "Epoch 472, Batch 100: Loss 0.848\n",
            "Epoch 472, Batch 150: Loss 0.809\n",
            "Epoch 472: Train Loss: 0.829\n",
            "Epoch 472: Test Accuracy: 97.05%\n",
            "Epoch 473, Batch 50: Loss 0.912\n",
            "Epoch 473, Batch 100: Loss 0.833\n",
            "Epoch 473, Batch 150: Loss 0.774\n",
            "Epoch 473: Train Loss: 0.850\n",
            "Epoch 473: Test Accuracy: 96.91%\n",
            "Epoch 474, Batch 50: Loss 0.922\n",
            "Epoch 474, Batch 100: Loss 0.824\n",
            "Epoch 474, Batch 150: Loss 0.809\n",
            "Epoch 474: Train Loss: 0.838\n",
            "Epoch 474: Test Accuracy: 97.19%\n",
            "Epoch 475, Batch 50: Loss 0.891\n",
            "Epoch 475, Batch 100: Loss 0.913\n",
            "Epoch 475, Batch 150: Loss 0.911\n",
            "Epoch 475: Train Loss: 0.892\n",
            "Epoch 475: Test Accuracy: 96.97%\n",
            "Model saved at epoch 475.\n",
            "Epoch 476, Batch 50: Loss 0.847\n",
            "Epoch 476, Batch 100: Loss 0.811\n",
            "Epoch 476, Batch 150: Loss 0.967\n",
            "Epoch 476: Train Loss: 0.889\n",
            "Epoch 476: Test Accuracy: 97.07%\n",
            "Epoch 477, Batch 50: Loss 0.893\n",
            "Epoch 477, Batch 100: Loss 0.778\n",
            "Epoch 477, Batch 150: Loss 0.759\n",
            "Epoch 477: Train Loss: 0.800\n",
            "Epoch 477: Test Accuracy: 97.17%\n",
            "Epoch 478, Batch 50: Loss 0.780\n",
            "Epoch 478, Batch 100: Loss 0.857\n",
            "Epoch 478, Batch 150: Loss 0.842\n",
            "Epoch 478: Train Loss: 0.853\n",
            "Epoch 478: Test Accuracy: 97.13%\n",
            "Epoch 479, Batch 50: Loss 0.829\n",
            "Epoch 479, Batch 100: Loss 0.899\n",
            "Epoch 479, Batch 150: Loss 0.863\n",
            "Epoch 479: Train Loss: 0.875\n",
            "Epoch 479: Test Accuracy: 97.18%\n",
            "Epoch 480, Batch 50: Loss 0.849\n",
            "Epoch 480, Batch 100: Loss 0.779\n",
            "Epoch 480, Batch 150: Loss 0.929\n",
            "Epoch 480: Train Loss: 0.846\n",
            "Epoch 480: Test Accuracy: 97.20%\n",
            "Model saved at epoch 480.\n",
            "Epoch 481, Batch 50: Loss 0.882\n",
            "Epoch 481, Batch 100: Loss 0.934\n",
            "Epoch 481, Batch 150: Loss 0.847\n",
            "Epoch 481: Train Loss: 0.897\n",
            "Epoch 481: Test Accuracy: 97.01%\n",
            "Epoch 482, Batch 50: Loss 0.878\n",
            "Epoch 482, Batch 100: Loss 0.883\n",
            "Epoch 482, Batch 150: Loss 0.888\n",
            "Epoch 482: Train Loss: 0.871\n",
            "Epoch 482: Test Accuracy: 97.16%\n",
            "Epoch 483, Batch 50: Loss 0.911\n",
            "Epoch 483, Batch 100: Loss 0.831\n",
            "Epoch 483, Batch 150: Loss 0.786\n",
            "Epoch 483: Train Loss: 0.856\n",
            "Epoch 483: Test Accuracy: 97.08%\n",
            "Epoch 484, Batch 50: Loss 0.863\n",
            "Epoch 484, Batch 100: Loss 0.852\n",
            "Epoch 484, Batch 150: Loss 0.859\n",
            "Epoch 484: Train Loss: 0.845\n",
            "Epoch 484: Test Accuracy: 97.00%\n",
            "Epoch 485, Batch 50: Loss 0.933\n",
            "Epoch 485, Batch 100: Loss 0.871\n",
            "Epoch 485, Batch 150: Loss 0.843\n",
            "Epoch 485: Train Loss: 0.864\n",
            "Epoch 485: Test Accuracy: 97.17%\n",
            "Model saved at epoch 485.\n",
            "Epoch 486, Batch 50: Loss 0.893\n",
            "Epoch 486, Batch 100: Loss 0.917\n",
            "Epoch 486, Batch 150: Loss 0.893\n",
            "Epoch 486: Train Loss: 0.906\n",
            "Epoch 486: Test Accuracy: 97.09%\n",
            "Epoch 487, Batch 50: Loss 0.830\n",
            "Epoch 487, Batch 100: Loss 0.897\n",
            "Epoch 487, Batch 150: Loss 0.896\n",
            "Epoch 487: Train Loss: 0.881\n",
            "Epoch 487: Test Accuracy: 97.13%\n",
            "Epoch 488, Batch 50: Loss 0.879\n",
            "Epoch 488, Batch 100: Loss 0.873\n",
            "Epoch 488, Batch 150: Loss 0.939\n",
            "Epoch 488: Train Loss: 0.892\n",
            "Epoch 488: Test Accuracy: 97.08%\n",
            "Epoch 489, Batch 50: Loss 0.813\n",
            "Epoch 489, Batch 100: Loss 0.865\n",
            "Epoch 489, Batch 150: Loss 0.908\n",
            "Epoch 489: Train Loss: 0.855\n",
            "Epoch 489: Test Accuracy: 97.14%\n",
            "Epoch 490, Batch 50: Loss 0.916\n",
            "Epoch 490, Batch 100: Loss 0.814\n",
            "Epoch 490, Batch 150: Loss 0.949\n",
            "Epoch 490: Train Loss: 0.890\n",
            "Epoch 490: Test Accuracy: 97.14%\n",
            "Model saved at epoch 490.\n",
            "Epoch 491, Batch 50: Loss 0.893\n",
            "Epoch 491, Batch 100: Loss 0.939\n",
            "Epoch 491, Batch 150: Loss 0.840\n",
            "Epoch 491: Train Loss: 0.884\n",
            "Epoch 491: Test Accuracy: 97.17%\n",
            "Epoch 492, Batch 50: Loss 0.771\n",
            "Epoch 492, Batch 100: Loss 0.876\n",
            "Epoch 492, Batch 150: Loss 0.820\n",
            "Epoch 492: Train Loss: 0.827\n",
            "Epoch 492: Test Accuracy: 97.10%\n",
            "Epoch 493, Batch 50: Loss 0.837\n",
            "Epoch 493, Batch 100: Loss 0.896\n",
            "Epoch 493, Batch 150: Loss 0.925\n",
            "Epoch 493: Train Loss: 0.890\n",
            "Epoch 493: Test Accuracy: 97.08%\n",
            "Epoch 494, Batch 50: Loss 0.773\n",
            "Epoch 494, Batch 100: Loss 0.905\n",
            "Epoch 494, Batch 150: Loss 0.839\n",
            "Epoch 494: Train Loss: 0.852\n",
            "Epoch 494: Test Accuracy: 97.18%\n",
            "Epoch 495, Batch 50: Loss 0.895\n",
            "Epoch 495, Batch 100: Loss 0.861\n",
            "Epoch 495, Batch 150: Loss 0.869\n",
            "Epoch 495: Train Loss: 0.868\n",
            "Epoch 495: Test Accuracy: 97.07%\n",
            "Model saved at epoch 495.\n",
            "Epoch 496, Batch 50: Loss 0.871\n",
            "Epoch 496, Batch 100: Loss 0.895\n",
            "Epoch 496, Batch 150: Loss 0.756\n",
            "Epoch 496: Train Loss: 0.852\n",
            "Epoch 496: Test Accuracy: 97.09%\n",
            "Epoch 497, Batch 50: Loss 0.837\n",
            "Epoch 497, Batch 100: Loss 0.891\n",
            "Epoch 497, Batch 150: Loss 0.862\n",
            "Epoch 497: Train Loss: 0.867\n",
            "Epoch 497: Test Accuracy: 97.14%\n",
            "Epoch 498, Batch 50: Loss 0.866\n",
            "Epoch 498, Batch 100: Loss 0.855\n",
            "Epoch 498, Batch 150: Loss 0.884\n",
            "Epoch 498: Train Loss: 0.881\n",
            "Epoch 498: Test Accuracy: 97.10%\n",
            "Epoch 499, Batch 50: Loss 0.837\n",
            "Epoch 499, Batch 100: Loss 0.883\n",
            "Epoch 499, Batch 150: Loss 0.827\n",
            "Epoch 499: Train Loss: 0.853\n",
            "Epoch 499: Test Accuracy: 97.08%\n",
            "Epoch 500, Batch 50: Loss 0.840\n",
            "Epoch 500, Batch 100: Loss 0.778\n",
            "Epoch 500, Batch 150: Loss 0.824\n",
            "Epoch 500: Train Loss: 0.825\n",
            "Epoch 500: Test Accuracy: 97.26%\n",
            "Model saved at epoch 500.\n",
            "Training finished!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Training Loss: 0.825\n",
            "Final Test Accuracy: 97.26%\n",
            "Total Trainable Parameters: 4359242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "import torchvision.transforms as T\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = PreActSEResNet20().to(device)\n",
        "checkpoint_path = 'model.pth'\n",
        "net.load_state_dict(torch.load(checkpoint_path, map_location=device, weights_only=True))\n",
        "net.eval()\n",
        "\n",
        "with open('cifar_test_nolabel.pkl', 'rb') as f:\n",
        "    test_dict = pickle.load(f)\n",
        "\n",
        "# Extract images and IDs from the dictionary\n",
        "images = test_dict[b'data']\n",
        "ids = test_dict[b'ids']\n",
        "\n",
        "# Check if images need reshaping.\n",
        "if len(images.shape) == 2 and images.shape[1] == 3072:\n",
        "    images = images.reshape(-1, 3, 32, 32)\n",
        "elif len(images.shape) == 3:\n",
        "    images = np.transpose(images, (0, 3, 1, 2))\n",
        "\n",
        "test_transform = T.Compose([\n",
        "    T.ToPILImage(),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "])\n",
        "\n",
        "# Create a dataset for the test images using the extracted images\n",
        "class CIFAR10TestDataset(data.Dataset):\n",
        "    def __init__(self, images, transform=None):\n",
        "        self.images = images\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the image as a NumPy array\n",
        "        img = self.images[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img\n",
        "\n",
        "test_dataset = CIFAR10TestDataset(images, transform=test_transform)\n",
        "test_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Run inference and collect predictions\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for batch_imgs in test_loader:\n",
        "        batch_imgs = batch_imgs.to(device)\n",
        "        outputs = net(batch_imgs)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "assert len(all_preds) == len(ids), \"Mismatch between predictions and provided IDs!\"\n",
        "\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'ID': ids,\n",
        "    'Label': all_preds\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv('prediction.csv', index=False)\n",
        "print(\"Submission file 'prediction.csv' generated successfully.\")"
      ],
      "metadata": {
        "id": "bs_A3PZRsYSo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa147de-0306-48c9-de88-67f024c8b981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file 'prediction.csv' generated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"Yog-Sothothe\""
      ],
      "metadata": {
        "id": "9UrvHb0RTZdg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Yog-Sothothe/DL-Project-1.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT_mzbwpThze",
        "outputId": "4890a158-1c28-4e47-85df-8cdd3fdbaf2d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DL-Project-1'...\n",
            "warning: You appear to have cloned an empty repository.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCdN63xfT47v",
        "outputId": "9101d2e4-9f87-4db5-ea43-a9d371e9e6e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/Copy': No such file or directory\n",
            "cp: cannot stat 'of': No such file or directory\n",
            "cp: cannot stat 'Untitled9.ipynb': No such file or directory\n"
          ]
        }
      ]
    }
  ]
}